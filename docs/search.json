[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Social Data Analysis: An Introduction (Wprowadzenie do analizy danych społecznych)",
    "section": "",
    "text": "Preface\nThis is a Quarto book.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "",
    "text": "1.1 What is Data Science?\nData science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#what-is-data-science",
    "href": "chapter1.html#what-is-data-science",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "",
    "text": "Key Point\n\n\n\nIn social sciences, data science combines statistical methods, computational tools, and domain expertise to analyze complex social phenomena and human behavior.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#the-relationship-between-statistics-and-data-science",
    "href": "chapter1.html#the-relationship-between-statistics-and-data-science",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "1.2 The Relationship Between Statistics and Data Science",
    "text": "1.2 The Relationship Between Statistics and Data Science\nWhile statistics and data science are closely related, they have some distinctions:\n\nStatisticsData Science\n\n\n\nFocuses on mathematical theories and methods for collecting, analyzing, interpreting, and presenting data\nEmphasizes statistical inference, hypothesis testing, and probability theory\nHas a long history in social sciences for analyzing survey data, experimental results, and observational studies\n\n\n\n\nIncorporates statistical methods along with computer science and domain expertise\nEmphasizes big data, machine learning, and predictive modeling\nIn social sciences, often deals with large-scale digital traces, social media data, and complex behavioral datasets\n\n\n\n\nData science can be seen as an evolution and expansion of traditional statistics, incorporating new technologies and methodologies to handle larger and more complex social science datasets.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#essential-concepts-in-data-science-and-statistics",
    "href": "chapter1.html#essential-concepts-in-data-science-and-statistics",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "1.3 Essential Concepts in Data Science and Statistics",
    "text": "1.3 Essential Concepts in Data Science and Statistics\n\n1.3.1 Statistical Population, Sample, and Data Generating Process\nUnderstanding the relationships between population, sample, and the data generating process (DGP) is crucial in social science research.\n\n\n\n\n\n\nDefinitions\n\n\n\n\nPopulation: The entire group of individuals or objects about which information is sought.\nSample: A subset of the population that is selected for study.\nData Generating Process (DGP): The underlying mechanism or system that produces the observed data.\n\n\n\n\n1.3.1.1 Comparing Population and DGP:\n\nThe population represents the group we want to study, while the DGP is the mechanism producing the characteristics we observe in that population.\nIn social sciences, the DGP often involves complex social, psychological, and economic factors that shape the population’s characteristics.\nUnderstanding the DGP helps us interpret why the population has certain characteristics and how these might change over time or in different contexts.\n\n\n\n\n\n\n\nExample: Voter Behavior Study\n\n\n\n\nPopulation: All eligible voters in a country\nSample: 1000 randomly selected eligible voters\nDGP: The complex interplay of factors influencing voting decisions, such as political beliefs, economic conditions, media exposure, and social networks.\n\nUnderstanding the DGP helps researchers interpret voter behavior and potentially predict future trends.\n\n\nLet’s visualize this concept using R:\n\n\nClick to show/hide R code\nlibrary(ggplot2)\n\n# Simulate a population based on a simple DGP\nset.seed(123)\nage &lt;- rnorm(10000, mean = 45, sd = 15)\nincome &lt;- exp(rnorm(10000, mean = 10, sd = 0.5))\nvoting_prob &lt;- plogis(-5 + 0.05 * age + 0.00003 * income + rnorm(10000, sd = 0.5))\npopulation &lt;- data.frame(age = age, income = income, voting_prob = voting_prob)\n\n# Take a random sample\nsample_indices &lt;- sample(1:nrow(population), 1000)\nsample_data &lt;- population[sample_indices, ]\n\n# Visualize\nggplot(sample_data, aes(x = age, y = income, color = voting_prob)) +\n  geom_point(alpha = 0.6) +\n  scale_color_viridis_c() +\n  labs(title = \"Sample: Age, Income, and Voting Probability\",\n       x = \"Age\", y = \"Income\", color = \"Voting Probability\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis visualization demonstrates how age and income (part of the DGP) influence voting probability in our simulated population, based on the sample we’ve drawn.\n\n\n\n1.3.2 Types of Data in Social Sciences\nSocial science research deals with various types of data:\n\nQuantitative Data: Numerical data (e.g., survey responses, economic indicators)\nQualitative Data: Non-numerical data (e.g., interview transcripts, open-ended survey responses)\nBig Data: Large-scale digital traces (e.g., social media posts, online behavior logs)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#core-components-of-data-science-in-social-research",
    "href": "chapter1.html#core-components-of-data-science-in-social-research",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "1.4 Core Components of Data Science in Social Research",
    "text": "1.4 Core Components of Data Science in Social Research\n\nData CollectionData ProcessingExploratory Data Analysis (EDA)Statistical InferenceMachine Learning ApplicationsData Visualization and Communication\n\n\n\nSurveys and questionnaires\nInterviews and focus groups\nDigital data collection (e.g., web scraping, API access)\nEthical considerations in data collection\n\n\n\n\nCleaning and preprocessing data\nHandling missing values and outliers\nCoding qualitative data\nData transformation and normalization\n\n\n\n\nDescriptive statistics\nData visualization\nIdentifying patterns and trends in social phenomena\n\n\n\n\nHypothesis testing in social research\nRegression analysis\nCausal inference techniques\n\n\n\n\nPredictive modeling of social behaviors\nText analysis and sentiment analysis\nNetwork analysis in social contexts\n\n\n\n\nCreating effective visualizations for social science data\nCommunicating research findings to diverse audiences\nData-driven storytelling",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#tools-for-data-science-in-social-sciences",
    "href": "chapter1.html#tools-for-data-science-in-social-sciences",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "1.5 Tools for Data Science in Social Sciences",
    "text": "1.5 Tools for Data Science in Social Sciences\nIn this course, we’ll primarily use R for our data analysis, as it’s widely used in social science research.\n\n1.5.1 R for Social Science Data Analysis\nR offers powerful capabilities for social science research, from data manipulation to advanced statistical modeling.\n\n\nClick to show/hide R code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nClick to show/hide R code\n# Generate some example social science data\nset.seed(456)\nn &lt;- 500\ndata &lt;- tibble(\n  age = rnorm(n, mean = 35, sd = 12),\n  education_years = rpois(n, lambda = 13),\n  income = exp(rnorm(n, mean = 10, sd = 0.5)),\n  job_satisfaction = runif(n, min = 1, max = 5)\n)\n\n# Basic data summary\nsummary(data)\n\n\n      age        education_years     income      job_satisfaction\n Min.   : 6.42   Min.   : 4.00   Min.   : 4984   Min.   :1.002   \n 1st Qu.:27.77   1st Qu.:11.00   1st Qu.:15777   1st Qu.:2.017   \n Median :36.02   Median :13.00   Median :21799   Median :3.075   \n Mean   :36.18   Mean   :13.11   Mean   :24407   Mean   :3.049   \n 3rd Qu.:44.77   3rd Qu.:15.25   3rd Qu.:30653   3rd Qu.:4.033   \n Max.   :71.11   Max.   :25.00   Max.   :85257   Max.   :4.975   \n\n\nClick to show/hide R code\n# Correlation analysis\ncor(data)\n\n\n                          age education_years       income job_satisfaction\nage               1.000000000     0.001720991 -0.006960666     -0.044538735\neducation_years   0.001720991     1.000000000  0.038952942      0.002780209\nincome           -0.006960666     0.038952942  1.000000000      0.000761065\njob_satisfaction -0.044538735     0.002780209  0.000761065      1.000000000\n\n\nClick to show/hide R code\n# Visualization\nggplot(data, aes(x = education_years, y = income)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Relationship between Education and Income\",\n       x = \"Years of Education\", y = \"Income\") +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis example demonstrates basic data manipulation, summary statistics, and visualization using R, which are common tasks in social science research.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#ethical-considerations-in-social-science-data-analysis",
    "href": "chapter1.html#ethical-considerations-in-social-science-data-analysis",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "1.6 Ethical Considerations in Social Science Data Analysis",
    "text": "1.6 Ethical Considerations in Social Science Data Analysis\nEthics play a crucial role in social science research:\n\nPrivacy and Consent: Ensuring participant privacy and informed consent\nData Protection: Securely storing and managing sensitive personal data\nBias and Representation: Addressing sampling bias and ensuring diverse representation\nTransparency: Clearly communicating research methods and limitations\nSocial Impact: Considering the potential societal implications of research findings\n\n\n\n\n\n\n\nImportant\n\n\n\nSocial scientists must carefully consider the ethical implications of their data collection, analysis, and dissemination practices.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#key-takeaways",
    "href": "chapter1.html#key-takeaways",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "1.7 Key Takeaways",
    "text": "1.7 Key Takeaways\n\nData science in social sciences builds upon traditional statistical methods, incorporating new technologies to analyze complex social phenomena.\nUnderstanding concepts like population, sample, and data generating processes is crucial for valid social science research.\nThe data science process in social research involves multiple steps from ethical data collection to the communication of insights.\nR is a powerful tool for social science data analysis, offering a wide range of capabilities.\nEthical considerations should be at the forefront of any social science data project.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter1.html#next-steps",
    "href": "chapter1.html#next-steps",
    "title": "1  Introduction to Data Science and Statistics for Social Sciences",
    "section": "1.8 Next Steps",
    "text": "1.8 Next Steps\nIn the following chapters, we’ll dive deeper into each component of the data science process, exploring statistical concepts, R programming techniques, and real-world applications in social science research.\n\n\n\n\n\n\nPractice Exercise\n\n\n\nUsing the concepts learned in this chapter, design a small-scale study on a social science topic of your choice. Identify the population, consider how you would draw a sample, and reflect on the potential data generating process. What ethical considerations would you need to address?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data Science and Statistics for Social Sciences</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html",
    "href": "rozdzial1.html",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "",
    "text": "2.1 Czym jest Nauka o Danych?\nNauka o danych to interdyscyplinarna dziedzina, która wykorzystuje metody naukowe, procesy, algorytmy i systemy do wydobywania wiedzy i wglądów ze strukturalnych i niestrukturalnych danych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#czym-jest-nauka-o-danych",
    "href": "rozdzial1.html#czym-jest-nauka-o-danych",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "",
    "text": "Kluczowy Punkt\n\n\n\nW naukach społecznych nauka o danych łączy metody statystyczne, narzędzia obliczeniowe i wiedzę dziedzinową do analizy złożonych zjawisk społecznych i zachowań ludzkich.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#związek-między-statystyką-a-nauką-o-danych",
    "href": "rozdzial1.html#związek-między-statystyką-a-nauką-o-danych",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "2.2 Związek Między Statystyką a Nauką o Danych",
    "text": "2.2 Związek Między Statystyką a Nauką o Danych\nChociaż statystyka i nauka o danych są ściśle powiązane, mają pewne różnice:\n\nStatystykaNauka o Danych\n\n\n\nKoncentruje się na teoriach matematycznych i metodach zbierania, analizowania, interpretowania i prezentowania danych\nKładzie nacisk na wnioskowanie statystyczne, testowanie hipotez i teorię prawdopodobieństwa\nMa długą historię w naukach społecznych w analizie danych ankietowych, wyników eksperymentalnych i badań obserwacyjnych\n\n\n\n\nŁączy metody statystyczne z informatyką i wiedzą dziedzinową\nKładzie nacisk na big data, uczenie maszynowe i modelowanie predykcyjne\nW naukach społecznych często zajmuje się danymi cyfrowymi na dużą skalę, danymi z mediów społecznościowych i złożonymi zbiorami danych behawioralnych\n\n\n\n\nNauka o danych może być postrzegana jako ewolucja i rozszerzenie tradycyjnej statystyki, włączając nowe technologie i metodologie do obsługi większych i bardziej złożonych zbiorów danych w naukach społecznych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#podstawowe-koncepcje-w-nauce-o-danych-i-statystyce",
    "href": "rozdzial1.html#podstawowe-koncepcje-w-nauce-o-danych-i-statystyce",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "2.3 Podstawowe Koncepcje w Nauce o Danych i Statystyce",
    "text": "2.3 Podstawowe Koncepcje w Nauce o Danych i Statystyce\n\n2.3.1 Populacja Statystyczna, Próba i Proces Generowania Danych\nZrozumienie relacji między populacją, próbą i procesem generowania danych (PGD) jest kluczowe w badaniach nauk społecznych.\n\n\n\n\n\n\nDefinicje\n\n\n\n\nPopulacja: Cała grupa osób lub obiektów, o których poszukuje się informacji.\nPróba: Podzbiór populacji, który jest wybierany do badania.\nProces Generowania Danych (PGD): Podstawowy mechanizm lub system, który produkuje obserwowane dane.\n\n\n\n\n2.3.1.1 Porównanie Populacji i PGD:\n\nPopulacja reprezentuje grupę, którą chcemy badać, podczas gdy PGD jest mechanizmem produkującym cechy, które obserwujemy w tej populacji.\nW naukach społecznych PGD często obejmuje złożone czynniki społeczne, psychologiczne i ekonomiczne, które kształtują cechy populacji.\nZrozumienie PGD pomaga nam interpretować, dlaczego populacja ma pewne cechy i jak mogą się one zmieniać w czasie lub w różnych kontekstach.\n\n\n\n\n\n\n\nPrzykład: Badanie Zachowań Wyborczych\n\n\n\n\nPopulacja: Wszyscy uprawnieni wyborcy w kraju\nPróba: 1000 losowo wybranych uprawnionych wyborców\nPGD: Złożone współdziałanie czynników wpływających na decyzje wyborcze, takich jak przekonania polityczne, warunki ekonomiczne, ekspozycja na media i sieci społeczne.\n\nZrozumienie PGD pomaga badaczom interpretować zachowania wyborcze i potencjalnie przewidywać przyszłe trendy.\n\n\nZobrazujmy tę koncepcję za pomocą R:\n\n\nKliknij, aby pokazać/ukryć kod R\nlibrary(ggplot2)\n\n# Symulacja populacji na podstawie prostego PGD\nset.seed(123)\nwiek &lt;- rnorm(10000, mean = 45, sd = 15)\ndochod &lt;- exp(rnorm(10000, mean = 10, sd = 0.5))\nprawdopodobienstwo_glosowania &lt;- plogis(-5 + 0.05 * wiek + 0.00003 * dochod + rnorm(10000, sd = 0.5))\npopulacja &lt;- data.frame(wiek = wiek, dochod = dochod, prawdopodobienstwo_glosowania = prawdopodobienstwo_glosowania)\n\n# Wybór losowej próby\nindeksy_proby &lt;- sample(1:nrow(populacja), 1000)\ndane_proby &lt;- populacja[indeksy_proby, ]\n\n# Wizualizacja\nggplot(dane_proby, aes(x = wiek, y = dochod, color = prawdopodobienstwo_glosowania)) +\n  geom_point(alpha = 0.6) +\n  scale_color_viridis_c() +\n  labs(title = \"Próba: Wiek, Dochód i Prawdopodobieństwo Głosowania\",\n       x = \"Wiek\", y = \"Dochód\", color = \"Prawdopodobieństwo Głosowania\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nTa wizualizacja pokazuje, jak wiek i dochód (część PGD) wpływają na prawdopodobieństwo głosowania w naszej symulowanej populacji, na podstawie wybranej próby.\n\n\n\n2.3.2 Rodzaje Danych w Naukach Społecznych\nBadania w naukach społecznych zajmują się różnymi rodzajami danych:\n\nDane Ilościowe: Dane liczbowe (np. odpowiedzi z ankiet, wskaźniki ekonomiczne)\nDane Jakościowe: Dane nieliczbowe (np. transkrypcje wywiadów, odpowiedzi na pytania otwarte w ankietach)\nBig Data: Dane cyfrowe na dużą skalę (np. posty w mediach społecznościowych, logi zachowań online)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#główne-komponenty-nauki-o-danych-w-badaniach-społecznych",
    "href": "rozdzial1.html#główne-komponenty-nauki-o-danych-w-badaniach-społecznych",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "2.4 Główne Komponenty Nauki o Danych w Badaniach Społecznych",
    "text": "2.4 Główne Komponenty Nauki o Danych w Badaniach Społecznych\n\nZbieranie DanychPrzetwarzanie DanychEksploracyjna Analiza Danych (EDA)Wnioskowanie StatystyczneZastosowania Uczenia MaszynowegoWizualizacja Danych i Komunikacja\n\n\n\nAnkiety i kwestionariusze\nWywiady i grupy fokusowe\nZbieranie danych cyfrowych (np. web scraping, dostęp do API)\nEtyczne aspekty zbierania danych\n\n\n\n\nCzyszczenie i wstępne przetwarzanie danych\nObsługa brakujących wartości i wartości odstających\nKodowanie danych jakościowych\nTransformacja i normalizacja danych\n\n\n\n\nStatystyki opisowe\nWizualizacja danych\nIdentyfikacja wzorców i trendów w zjawiskach społecznych\n\n\n\n\nTestowanie hipotez w badaniach społecznych\nAnaliza regresji\nTechniki wnioskowania przyczynowego\n\n\n\n\nModelowanie predykcyjne zachowań społecznych\nAnaliza tekstu i analiza sentymentu\nAnaliza sieci w kontekstach społecznych\n\n\n\n\nTworzenie efektywnych wizualizacji dla danych z nauk społecznych\nKomunikowanie wyników badań różnym odbiorcom\nStorytelling oparty na danych",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#narzędzia-do-nauki-o-danych-w-naukach-społecznych",
    "href": "rozdzial1.html#narzędzia-do-nauki-o-danych-w-naukach-społecznych",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "2.5 Narzędzia do Nauki o Danych w Naukach Społecznych",
    "text": "2.5 Narzędzia do Nauki o Danych w Naukach Społecznych\nW tym kursie będziemy głównie używać R do naszej analizy danych, ponieważ jest on szeroko stosowany w badaniach nauk społecznych.\n\n2.5.1 R w Analizie Danych Nauk Społecznych\nR oferuje potężne możliwości dla badań w naukach społecznych, od manipulacji danymi po zaawansowane modelowanie statystyczne.\n\n\nKliknij, aby pokazać/ukryć kod R\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nKliknij, aby pokazać/ukryć kod R\n# Generowanie przykładowych danych z nauk społecznych\nset.seed(456)\nn &lt;- 500\ndane &lt;- tibble(\n  wiek = rnorm(n, mean = 35, sd = 12),\n  lata_edukacji = rpois(n, lambda = 13),\n  dochod = exp(rnorm(n, mean = 10, sd = 0.5)),\n  satysfakcja_z_pracy = runif(n, min = 1, max = 5)\n)\n\n# Podstawowe podsumowanie danych\nsummary(dane)\n\n\n      wiek       lata_edukacji       dochod      satysfakcja_z_pracy\n Min.   : 6.42   Min.   : 4.00   Min.   : 4984   Min.   :1.002      \n 1st Qu.:27.77   1st Qu.:11.00   1st Qu.:15777   1st Qu.:2.017      \n Median :36.02   Median :13.00   Median :21799   Median :3.075      \n Mean   :36.18   Mean   :13.11   Mean   :24407   Mean   :3.049      \n 3rd Qu.:44.77   3rd Qu.:15.25   3rd Qu.:30653   3rd Qu.:4.033      \n Max.   :71.11   Max.   :25.00   Max.   :85257   Max.   :4.975      \n\n\nKliknij, aby pokazać/ukryć kod R\n# Analiza korelacji\ncor(dane)\n\n\n                            wiek lata_edukacji       dochod satysfakcja_z_pracy\nwiek                 1.000000000   0.001720991 -0.006960666        -0.044538735\nlata_edukacji        0.001720991   1.000000000  0.038952942         0.002780209\ndochod              -0.006960666   0.038952942  1.000000000         0.000761065\nsatysfakcja_z_pracy -0.044538735   0.002780209  0.000761065         1.000000000\n\n\nKliknij, aby pokazać/ukryć kod R\n# Wizualizacja\nggplot(dane, aes(x = lata_edukacji, y = dochod)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Zależność między Edukacją a Dochodem\",\n       x = \"Lata Edukacji\", y = \"Dochód\") +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nTen przykład demonstruje podstawową manipulację danymi, statystyki opisowe i wizualizację przy użyciu R, które są powszechnymi zadaniami w badaniach nauk społecznych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#etyczne-aspekty-w-analizie-danych-nauk-społecznych",
    "href": "rozdzial1.html#etyczne-aspekty-w-analizie-danych-nauk-społecznych",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "2.6 Etyczne Aspekty w Analizie Danych Nauk Społecznych",
    "text": "2.6 Etyczne Aspekty w Analizie Danych Nauk Społecznych\nEtyka odgrywa kluczową rolę w badaniach nauk społecznych:\n\nPrywatność i Zgoda: Zapewnienie prywatności uczestników i świadomej zgody\nOchrona Danych: Bezpieczne przechowywanie i zarządzanie wrażliwymi danymi osobowymi\nBłędy i Reprezentacja: Adresowanie błędów próbkowania i zapewnienie różnorodnej reprezentacji\nPrzejrzystość: Jasne komunikowanie metod badawczych i ograniczeń\nWpływ Społeczny: Rozważanie potencjalnych społecznych implikacji wyników badań\n\n\n\n\n\n\n\nWażne\n\n\n\nNaukowcy społeczni muszą starannie rozważyć etyczne implikacje swoich praktyk zbierania, analizy i rozpowszechniania danych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#kluczowe-wnioski",
    "href": "rozdzial1.html#kluczowe-wnioski",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "2.7 Kluczowe Wnioski",
    "text": "2.7 Kluczowe Wnioski\n\nNauka o danych w naukach społecznych bazuje na tradycyjnych metodach statystycznych, włączając nowe technologie do analizy złożonych zjawisk społecznych.\nZrozumienie koncepcji takich jak populacja, próba i procesy generowania danych jest kluczowe dla prawidłowych badań w naukach społecznych.\nProces nauki o danych w badaniach społecznych obejmuje wiele etapów, od etycznego zbierania danych po komunikację wniosków.\nR jest potężnym narzędziem do analizy danych w naukach społecznych, oferującym szeroki zakres możliwości.\nAspekty etyczne powinny być na pierwszym planie każdego projektu związanego z danymi w naukach społecznych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial1.html#następne-kroki",
    "href": "rozdzial1.html#następne-kroki",
    "title": "2  Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych",
    "section": "2.8 Następne Kroki",
    "text": "2.8 Następne Kroki\nW kolejnych rozdziałach zagłębimy się w każdy komponent procesu nauki o danych, badając koncepcje statystyczne, techniki programowania w R i rzeczywiste zastosowania w badaniach nauk społecznych.\n\n\n\n\n\n\nĆwiczenie Praktyczne\n\n\n\nWykorzystując koncepcje poznane w tym rozdziale, zaprojektuj małe badanie na wybrany temat z nauk społecznych. Określ populację, zastanów się, jak wybrałbyś próbę i przemyśl potencjalny proces generowania danych. Jakie aspekty etyczne należałoby uwzględnić?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Wprowadzenie do Nauki o Danych i Statystyki dla Nauk Społecznych</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "3  Understanding Data Types in Social Sciences",
    "section": "",
    "text": "3.1 Introduction\nIn social science research, understanding the nature of our data is crucial for selecting appropriate analysis methods and drawing valid conclusions. This chapter explores fundamental concepts of data types, starting from basic mathematical set theory and progressing to practical applications in social science research.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Understanding Data Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter2.html#foundations-in-number-sets",
    "href": "chapter2.html#foundations-in-number-sets",
    "title": "3  Understanding Data Types in Social Sciences",
    "section": "3.2 Foundations in Number Sets",
    "text": "3.2 Foundations in Number Sets\nBefore diving into data types, it’s essential to understand the basic number sets that form the foundation of our understanding of data.\n\n3.2.1 Basic Number Sets\n\nNatural Numbers (ℕ): The counting numbers {1, 2, 3, …}\nIntegers (ℤ): Includes natural numbers, their negatives, and zero {…, -2, -1, 0, 1, 2, …}\nRational Numbers (ℚ): Numbers that can be expressed as a fraction of two integers\nReal Numbers (ℝ): All numbers on the number line, including rationals and irrationals\n\n\n\n3.2.2 Properties of Sets\n\nCountable Sets: Sets whose elements can be put in a one-to-one correspondence with the natural numbers. For example, the set of integers is countable.\nUncountable Sets: Sets that are not countable. The set of real numbers is uncountable.\nDiscrete Sets: Sets where each element is separated from other elements by a finite gap. The integers form a discrete set.\nDense Sets: Sets where between any two elements, there is always another element of the set. The rational numbers and real numbers are dense sets.\n\n\n\n\n\n\n\nNote\n\n\n\nUnderstanding these set properties is crucial for grasping the nature of different data types in social sciences.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Understanding Data Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter2.html#discrete-vs.-continuous-data",
    "href": "chapter2.html#discrete-vs.-continuous-data",
    "title": "3  Understanding Data Types in Social Sciences",
    "section": "3.3 Discrete vs. Continuous Data",
    "text": "3.3 Discrete vs. Continuous Data\nNow that we have a foundation in number sets, we can better understand the distinction between discrete and continuous data in social science research.\n\n3.3.1 Discrete Data\nDiscrete data corresponds to discrete sets in mathematics. It can only take on specific, separate values, often from a countable set.\nProperties of discrete data:\n\nValues are distinct and separate\nOften (but not always) represented by integers\nTypically counted rather than measured\nCan be finite or infinite\n\n\nExamples of discrete data in social sciences:\n\nNumber of children in a family (ℕ)\nEducational level (e.g., 1 = high school, 2 = bachelor’s, 3 = master’s)\nVoting choices in an election (e.g., 1 = Party A, 2 = Party B, 3 = Party C)\n\n\n\n\n3.3.2 Continuous Data\nContinuous data corresponds to dense sets in mathematics, typically represented by real numbers. It can take any value within a range.\nProperties of continuous data:\n\nValues can be any real number within a range\nRepresented by real numbers (ℝ)\nTypically measured rather than counted\nAlways infinite (in theory, though limited by measurement precision in practice)\n\n\nExamples of continuous data in social sciences:\n\nAge (can be any real number ≥ 0)\nIncome (can be any non-negative real number)\nTime spent on a task (can be any non-negative real number)\n\n\n\n\n3.3.3 Visualization of Discrete vs. Continuous Data\nLet’s visualize the difference using R:\n\n\nClick to show/hide R code\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Generate sample data\nset.seed(123)\ndiscrete_data &lt;- sample(1:5, 1000, replace = TRUE)\ncontinuous_data &lt;- rnorm(1000, mean = 3, sd = 1)\n\n# Create data frames\ndiscrete_df &lt;- data.frame(value = discrete_data, type = \"Discrete\")\ncontinuous_df &lt;- data.frame(value = continuous_data, type = \"Continuous\")\n\n# Discrete plot\np1 &lt;- ggplot(discrete_df, aes(x = value)) +\n  geom_bar() +\n  scale_x_continuous(breaks = 1:5) +\n  labs(title = \"Discrete Data\", x = \"Value\", y = \"Count\") +\n  theme_minimal()\n\n# Continuous plot\np2 &lt;- ggplot(continuous_df, aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Continuous Data\", x = \"Value\", y = \"Count\") +\n  theme_minimal()\n\n# Display plots side by side\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n3.3.4 The Continuum Between Discrete and Continuous\nIn practice, the distinction between discrete and continuous data can sometimes blur:\n\nDiscretized Continuous Data: Continuous variables that are rounded or grouped into categories (e.g., age groups, income brackets).\nHigh-Cardinality Discrete Data: Discrete variables with many possible values can approximate continuous data (e.g., ZIP codes, detailed occupation codes).\nLimited Precision Measurements: Continuous variables measured with limited precision appear discrete (e.g., temperature measured to the nearest degree).\n\n\n\n\n\n\n\nImportant\n\n\n\nThe choice to treat data as discrete or continuous often depends on the research context, measurement precision, and analytical goals.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Understanding Data Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter2.html#implications-for-social-science-research",
    "href": "chapter2.html#implications-for-social-science-research",
    "title": "3  Understanding Data Types in Social Sciences",
    "section": "3.4 Implications for Social Science Research",
    "text": "3.4 Implications for Social Science Research\nUnderstanding the nature of data as discrete or continuous, and their relationship to mathematical sets, has important implications for social science research:\n\nMeasurement and Operationalization: How we define and measure variables can influence whether they are treated as discrete or continuous.\nStatistical Analysis: Different statistical techniques are appropriate for discrete vs. continuous data. For example:\n\nDiscrete: Chi-square tests, logistic regression\nContinuous: t-tests, linear regression\n\nData Visualization: The choice of visualization technique depends on whether data is discrete or continuous (e.g., bar plots vs. histograms).\nInterpretation of Results: Understanding the discrete or continuous nature of data is crucial for correctly interpreting research findings and their implications.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Understanding Data Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter2.html#practical-exercise",
    "href": "chapter2.html#practical-exercise",
    "title": "3  Understanding Data Types in Social Sciences",
    "section": "3.5 Practical Exercise",
    "text": "3.5 Practical Exercise\nLet’s create a dataset that includes both discrete and continuous variables, and explore how their properties influence our analysis:\n\n\nClick to show/hide R code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nClick to show/hide R code\n# Create sample dataset\nset.seed(456)\nn &lt;- 200\n\ndata &lt;- tibble(\n  id = 1:n,\n  age = round(runif(n, 18, 65), 1),  # Continuous\n  income = round(rlnorm(n, meanlog = 10.5, sdlog = 0.5), 2),  # Continuous\n  education_years = sample(10:22, n, replace = TRUE),  # Discrete\n  job_satisfaction = sample(1:5, n, replace = TRUE)  # Discrete (Likert-type)\n)\n\n# Summary statistics\nsummary(data)\n\n\n       id              age            income       education_years\n Min.   :  1.00   Min.   :18.10   Min.   : 11039   Min.   :10.00  \n 1st Qu.: 50.75   1st Qu.:32.67   1st Qu.: 24964   1st Qu.:13.00  \n Median :100.50   Median :43.75   Median : 36294   Median :17.00  \n Mean   :100.50   Mean   :43.52   Mean   : 40536   Mean   :16.02  \n 3rd Qu.:150.25   3rd Qu.:55.42   3rd Qu.: 53754   3rd Qu.:19.00  \n Max.   :200.00   Max.   :64.70   Max.   :140046   Max.   :22.00  \n job_satisfaction\n Min.   :1.000   \n 1st Qu.:2.000   \n Median :3.000   \n Mean   :3.305   \n 3rd Qu.:4.000   \n Max.   :5.000   \n\n\nClick to show/hide R code\n# Visualizations\np1 &lt;- ggplot(data, aes(x = age)) +\n  geom_histogram(bins = 20, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Age Distribution (Continuous)\", x = \"Age\", y = \"Count\")\n\np2 &lt;- ggplot(data, aes(x = education_years)) +\n  geom_bar(fill = \"lightgreen\", color = \"black\") +\n  labs(title = \"Education Years (Discrete)\", x = \"Years of Education\", y = \"Count\")\n\np3 &lt;- ggplot(data, aes(x = income)) +\n  geom_histogram(bins = 30, fill = \"pink\", color = \"black\") +\n  labs(title = \"Income Distribution (Continuous)\", x = \"Income\", y = \"Count\")\n\np4 &lt;- ggplot(data, aes(x = factor(job_satisfaction))) +\n  geom_bar(fill = \"lightyellow\", color = \"black\") +\n  labs(title = \"Job Satisfaction (Discrete)\", x = \"Satisfaction Level\", y = \"Count\")\n\n# Arrange plots\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\n\n\n\nClick to show/hide R code\n# Correlation analysis (appropriate for continuous variables)\ncor(data$age, data$income)\n\n\n[1] 0.03168301\n\n\nClick to show/hide R code\n# Chi-square test (appropriate for discrete variables)\nchisq.test(table(data$education_years, data$job_satisfaction))\n\n\nWarning in chisq.test(table(data$education_years, data$job_satisfaction)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(data$education_years, data$job_satisfaction)\nX-squared = 51.754, df = 48, p-value = 0.3295",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Understanding Data Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter2.html#conclusion",
    "href": "chapter2.html#conclusion",
    "title": "3  Understanding Data Types in Social Sciences",
    "section": "3.6 Conclusion",
    "text": "3.6 Conclusion\nUnderstanding the fundamental properties of number sets and how they relate to discrete and continuous data is crucial in social science research. This knowledge informs our choices in measurement, analysis, and interpretation of data. As we’ve seen, while the mathematical distinction between discrete and continuous is clear, real-world data often exists on a continuum between these two types. Researchers must carefully consider the nature of their data when designing studies, choosing analytical methods, and drawing conclusions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Understanding Data Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter2.html#references",
    "href": "chapter2.html#references",
    "title": "3  Understanding Data Types in Social Sciences",
    "section": "3.7 References",
    "text": "3.7 References\n\nGentle, J. E. (2009). Computational statistics (Vol. 308). New York: Springer.\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677-680.\nAgresti, A. (2018). Statistical methods for the social sciences. Pearson.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Understanding Data Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "rozdzial2.html",
    "href": "rozdzial2.html",
    "title": "4  Zrozumienie Typów Danych w Naukach Społecznych",
    "section": "",
    "text": "4.1 Wprowadzenie\nW badaniach nauk społecznych zrozumienie natury naszych danych jest kluczowe dla wyboru odpowiednich metod analizy i wyciągania prawidłowych wniosków. Ten rozdział bada fundamentalne koncepcje typów danych, zaczynając od podstawowej teorii zbiorów matematycznych i przechodząc do praktycznych zastosowań w badaniach nauk społecznych.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zrozumienie Typów Danych w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial2.html#podstawy-zbiorów-liczbowych",
    "href": "rozdzial2.html#podstawy-zbiorów-liczbowych",
    "title": "4  Zrozumienie Typów Danych w Naukach Społecznych",
    "section": "4.2 Podstawy Zbiorów Liczbowych",
    "text": "4.2 Podstawy Zbiorów Liczbowych\nZanim zagłębimy się w typy danych, istotne jest zrozumienie podstawowych zbiorów liczbowych, które tworzą fundament naszego rozumienia danych.\n\n4.2.1 Podstawowe Zbiory Liczbowe\n\nLiczby Naturalne (ℕ): Liczby do liczenia {1, 2, 3, …}\nLiczby Całkowite (ℤ): Obejmują liczby naturalne, ich przeciwne i zero {…, -2, -1, 0, 1, 2, …}\nLiczby Wymierne (ℚ): Liczby, które można wyrazić jako iloraz dwóch liczb całkowitych\nLiczby Rzeczywiste (ℝ): Wszystkie liczby na osi liczbowej, włączając wymierne i niewymierne\n\n\n\n4.2.2 Właściwości Zbiorów\n\nZbiory Przeliczalne: Zbiory, których elementy można ustawić w odpowiedniości jeden-do-jednego z liczbami naturalnymi. Na przykład, zbiór liczb całkowitych jest przeliczalny.\nZbiory Nieprzeliczalne: Zbiory, które nie są przeliczalne. Zbiór liczb rzeczywistych jest nieprzeliczalny.\nZbiory Dyskretne: Zbiory, w których każdy element jest oddzielony od innych elementów skończoną przerwą. Liczby całkowite tworzą zbiór dyskretny.\nZbiory Gęste: Zbiory, w których między dowolnymi dwoma elementami zawsze znajduje się inny element tego zbioru. Liczby wymierne i rzeczywiste są zbiorami gęstymi.\n\n\n\n\n\n\n\nNote\n\n\n\nZrozumienie tych właściwości zbiorów jest kluczowe dla uchwycenia natury różnych typów danych w naukach społecznych.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zrozumienie Typów Danych w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial2.html#dane-dyskretne-vs.-dane-ciągłe",
    "href": "rozdzial2.html#dane-dyskretne-vs.-dane-ciągłe",
    "title": "4  Zrozumienie Typów Danych w Naukach Społecznych",
    "section": "4.3 Dane Dyskretne vs. Dane Ciągłe",
    "text": "4.3 Dane Dyskretne vs. Dane Ciągłe\nTeraz, gdy mamy podstawy w zbiorach liczbowych, możemy lepiej zrozumieć rozróżnienie między danymi dyskretnymi a ciągłymi w badaniach nauk społecznych.\n\n4.3.1 Dane Dyskretne\nDane dyskretne odpowiadają zbiorom dyskretnym w matematyce. Mogą przyjmować tylko określone, oddzielne wartości, często z przeliczalnego zbioru.\nWłaściwości danych dyskretnych:\n\nWartości są odrębne i oddzielne\nCzęsto (ale nie zawsze) reprezentowane przez liczby całkowite\nZazwyczaj liczone, a nie mierzone\nMogą być skończone lub nieskończone\n\n\nPrzykłady danych dyskretnych w naukach społecznych:\n\nLiczba dzieci w rodzinie (ℕ)\nPoziom wykształcenia (np. 1 = szkoła średnia, 2 = licencjat, 3 = magisterium)\nWybory wyborcze (np. 1 = Partia A, 2 = Partia B, 3 = Partia C)\n\n\n\n\n4.3.2 Dane Ciągłe\nDane ciągłe odpowiadają zbiorom gęstym w matematyce, typowo reprezentowanym przez liczby rzeczywiste. Mogą przyjmować dowolną wartość w danym zakresie.\nWłaściwości danych ciągłych:\n\nWartości mogą być dowolną liczbą rzeczywistą w danym zakresie\nReprezentowane przez liczby rzeczywiste (ℝ)\nZazwyczaj mierzone, a nie liczone\nZawsze nieskończone (w teorii, choć ograniczone precyzją pomiaru w praktyce)\n\n\nPrzykłady danych ciągłych w naukach społecznych:\n\nWiek (może być dowolną liczbą rzeczywistą ≥ 0)\nDochód (może być dowolną nieujemną liczbą rzeczywistą)\nCzas spędzony na zadaniu (może być dowolną nieujemną liczbą rzeczywistą)\n\n\n\n\n4.3.3 Wizualizacja Danych Dyskretnych vs. Ciągłych\nZobrazujmy różnicę przy użyciu R:\n\n\nKliknij, aby pokazać/ukryć kod R\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Generowanie przykładowych danych\nset.seed(123)\ndane_dyskretne &lt;- sample(1:5, 1000, replace = TRUE)\ndane_ciągłe &lt;- rnorm(1000, mean = 3, sd = 1)\n\n# Tworzenie ramek danych\ndf_dyskretne &lt;- data.frame(wartość = dane_dyskretne, typ = \"Dyskretne\")\ndf_ciągłe &lt;- data.frame(wartość = dane_ciągłe, typ = \"Ciągłe\")\n\n# Wykres dla danych dyskretnych\np1 &lt;- ggplot(df_dyskretne, aes(x = wartość)) +\n  geom_bar() +\n  scale_x_continuous(breaks = 1:5) +\n  labs(title = \"Dane Dyskretne\", x = \"Wartość\", y = \"Liczba\") +\n  theme_minimal()\n\n# Wykres dla danych ciągłych\np2 &lt;- ggplot(df_ciągłe, aes(x = wartość)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Dane Ciągłe\", x = \"Wartość\", y = \"Liczba\") +\n  theme_minimal()\n\n# Wyświetlanie wykresów obok siebie\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n4.3.4 Kontinuum Między Danymi Dyskretnymi a Ciągłymi\nW praktyce rozróżnienie między danymi dyskretnymi a ciągłymi może się czasami zacierać:\n\nDane Ciągłe Zdyskretyzowane: Zmienne ciągłe, które są zaokrąglone lub pogrupowane w kategorie (np. grupy wiekowe, przedziały dochodów).\nDane Dyskretne o Wysokiej Liczności: Zmienne dyskretne z wieloma możliwymi wartościami mogą przybliżać dane ciągłe (np. kody pocztowe, szczegółowe kody zawodów).\nPomiary o Ograniczonej Precyzji: Zmienne ciągłe mierzone z ograniczoną precyzją wydają się dyskretne (np. temperatura mierzona do najbliższego stopnia).\n\n\n\n\n\n\n\nImportant\n\n\n\nWybór traktowania danych jako dyskretnych lub ciągłych często zależy od kontekstu badawczego, precyzji pomiaru i celów analitycznych.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zrozumienie Typów Danych w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial2.html#implikacje-dla-badań-w-naukach-społecznych",
    "href": "rozdzial2.html#implikacje-dla-badań-w-naukach-społecznych",
    "title": "4  Zrozumienie Typów Danych w Naukach Społecznych",
    "section": "4.4 Implikacje dla Badań w Naukach Społecznych",
    "text": "4.4 Implikacje dla Badań w Naukach Społecznych\nZrozumienie natury danych jako dyskretnych lub ciągłych oraz ich związku ze zbiorami matematycznymi ma ważne implikacje dla badań w naukach społecznych:\n\nPomiar i Operacjonalizacja: Sposób, w jaki definiujemy i mierzymy zmienne, może wpływać na to, czy są one traktowane jako dyskretne czy ciągłe.\nAnaliza Statystyczna: Różne techniki statystyczne są odpowiednie dla danych dyskretnych vs. ciągłych. Na przykład:\n\nDyskretne: Testy chi-kwadrat, regresja logistyczna\nCiągłe: Testy t, regresja liniowa\n\nWizualizacja Danych: Wybór techniki wizualizacji zależy od tego, czy dane są dyskretne czy ciągłe (np. wykresy słupkowe vs. histogramy).\nInterpretacja Wyników: Zrozumienie dyskretnej lub ciągłej natury danych jest kluczowe dla prawidłowej interpretacji wyników badań i ich implikacji.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zrozumienie Typów Danych w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial2.html#ćwiczenie-praktyczne",
    "href": "rozdzial2.html#ćwiczenie-praktyczne",
    "title": "4  Zrozumienie Typów Danych w Naukach Społecznych",
    "section": "4.5 Ćwiczenie Praktyczne",
    "text": "4.5 Ćwiczenie Praktyczne\nStwórzmy zbiór danych, który zawiera zarówno zmienne dyskretne, jak i ciągłe, i zbadajmy, jak ich właściwości wpływają na naszą analizę:\n\n\nKliknij, aby pokazać/ukryć kod R\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nKliknij, aby pokazać/ukryć kod R\n# Tworzenie przykładowego zbioru danych\nset.seed(456)\nn &lt;- 200\n\ndane &lt;- tibble(\n  id = 1:n,\n  wiek = round(runif(n, 18, 65), 1),  # Ciągłe\n  dochód = round(rlnorm(n, meanlog = 10.5, sdlog = 0.5), 2),  # Ciągłe\n  lata_edukacji = sample(10:22, n, replace = TRUE),  # Dyskretne\n  satysfakcja_z_pracy = sample(1:5, n, replace = TRUE)  # Dyskretne (typu Likerta)\n)\n\n# Statystyki opisowe\nsummary(dane)\n\n\n       id              wiek           dochód       lata_edukacji  \n Min.   :  1.00   Min.   :18.10   Min.   : 11039   Min.   :10.00  \n 1st Qu.: 50.75   1st Qu.:32.67   1st Qu.: 24964   1st Qu.:13.00  \n Median :100.50   Median :43.75   Median : 36294   Median :17.00  \n Mean   :100.50   Mean   :43.52   Mean   : 40536   Mean   :16.02  \n 3rd Qu.:150.25   3rd Qu.:55.42   3rd Qu.: 53754   3rd Qu.:19.00  \n Max.   :200.00   Max.   :64.70   Max.   :140046   Max.   :22.00  \n satysfakcja_z_pracy\n Min.   :1.000      \n 1st Qu.:2.000      \n Median :3.000      \n Mean   :3.305      \n 3rd Qu.:4.000      \n Max.   :5.000      \n\n\nKliknij, aby pokazać/ukryć kod R\n# Wizualizacje\np1 &lt;- ggplot(dane, aes(x = wiek)) +\n  geom_histogram(bins = 20, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Rozkład Wieku (Ciągłe)\", x = \"Wiek\", y = \"Liczba\")\n\np2 &lt;- ggplot(dane, aes(x = lata_edukacji)) +\n  geom_bar(fill = \"lightgreen\", color = \"black\") +\n  labs(title = \"Lata Edukacji (Dyskretne)\", x = \"Lata Edukacji\", y = \"Liczba\")\n\np3 &lt;- ggplot(dane, aes(x = dochód)) +\n  geom_histogram(bins = 30, fill = \"pink\", color = \"black\") +\n  labs(title = \"Rozkład Dochodów (Ciągłe)\", x = \"Dochód\", y = \"Liczba\")\n\np4 &lt;- ggplot(dane, aes(x = factor(satysfakcja_z_pracy))) +\n  geom_bar(fill = \"lightyellow\", color = \"black\") +\n  labs(title = \"Satysfakcja z Pracy (Dyskretne)\", x = \"Poziom Satysfakcji\", y = \"Liczba\")\n\n# Układanie wykresów\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\n\n\n\nKliknij, aby pokazać/ukryć kod R\n# Analiza korelacji (odpowiednia dla zmiennych ciągłych)\ncor(dane$wiek, dane$dochód)\n\n\n[1] 0.03168301\n\n\nKliknij, aby pokazać/ukryć kod R\n# Test chi-kwadrat (odpowiedni dla zmiennych dyskretnych)\nchisq.test(table(dane$lata_edukacji, dane$satysfakcja_z_pracy))\n\n\nWarning in chisq.test(table(dane$lata_edukacji, dane$satysfakcja_z_pracy)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(dane$lata_edukacji, dane$satysfakcja_z_pracy)\nX-squared = 51.754, df = 48, p-value = 0.3295",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zrozumienie Typów Danych w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial2.html#podsumowanie",
    "href": "rozdzial2.html#podsumowanie",
    "title": "4  Zrozumienie Typów Danych w Naukach Społecznych",
    "section": "4.6 Podsumowanie",
    "text": "4.6 Podsumowanie\nZrozumienie fundamentalnych właściwości zbiorów liczbowych i ich związku z danymi dyskretnymi i ciągłymi jest kluczowe w badaniach nauk społecznych. Ta wiedza wpływa na nasze wybory w zakresie pomiaru, analizy i interpretacji danych. Jak widzieliśmy, podczas gdy matematyczne rozróżnienie między dyskretnym a ciągłym jest jasne, dane ze świata rzeczywistego często istnieją na kontinuum między tymi dwoma typami. Badacze muszą starannie rozważyć naturę swoich danych podczas projektowania badań, wyboru metod analitycznych i wyciągania wniosków.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zrozumienie Typów Danych w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial2.html#bibliografia",
    "href": "rozdzial2.html#bibliografia",
    "title": "4  Zrozumienie Typów Danych w Naukach Społecznych",
    "section": "4.7 Bibliografia",
    "text": "4.7 Bibliografia\n\nGentle, J. E. (2009). Computational statistics (Vol. 308). New York: Springer.\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677-680.\nAgresti, A. (2018). Statistical methods for the social sciences. Pearson.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Zrozumienie Typów Danych w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "",
    "text": "5.1 Introduction to Randomness\nRandomness is a cornerstone concept in statistics and scientific research. It refers to the unpredictability of individual outcomes, even when the overall pattern may be predictable. In the social sciences, understanding randomness is crucial for designing studies, collecting data, and interpreting results.\nConsider flipping a fair coin. While we know that the probability of getting heads is 50%, we can’t predict with certainty the outcome of any single flip. This unpredictability is the essence of randomness.\nExamples of random phenomena in social sciences include:\nUnderstanding randomness helps researchers distinguish between genuine effects and chance occurrences. For instance, if we observe a slight difference in test scores between two groups, randomness helps us determine whether this difference is likely due to a real effect or just chance variation.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#introduction-to-randomness",
    "href": "chapter3.html#introduction-to-randomness",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "",
    "text": "Participant Selection: In a psychology experiment studying reaction times, the order in which participants arrive at the lab may be random.\nEconomic Behavior: The daily fluctuations in stock prices often exhibit random patterns, influenced by countless unpredictable factors.\nSocial Interactions: The occurrence of chance encounters between individuals in a community can be considered random events.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#sampling-bridging-sample-and-population",
    "href": "chapter3.html#sampling-bridging-sample-and-population",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.2 Sampling: Bridging Sample and Population",
    "text": "5.2 Sampling: Bridging Sample and Population\nSampling is the process of selecting a subset (sample) from a larger group (population) to make inferences about the population. It’s a critical skill in social science research, as studying entire populations is often impractical, too expensive, or sometimes impossible.\nKey Terms:\n\nPopulation: The entire group about which we want to draw conclusions.\nSample: A subset of the population that we actually study.\nSampling Frame: The list or procedure used to identify all members of the population.\n\nExample: Suppose we want to study the job satisfaction of all teachers in the United States (the population). Instead of surveying millions of teachers, we might select a sample of 5,000 teachers from various states, school districts, and grade levels.\nRandomness in sampling helps ensure that the sample is representative of the population, reducing bias and allowing for more accurate inferences. This is why probability sampling methods, which we’ll discuss next, are often preferred in scientific research.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#sampling-methods",
    "href": "chapter3.html#sampling-methods",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.3 Sampling Methods",
    "text": "5.3 Sampling Methods\n\n5.3.1 Probability Sampling\nProbability sampling methods involve random selection, giving each member of the population a known, non-zero chance of being selected.\n\nSimple Random Sampling: Each member of the population has an equal chance of being selected.\nExample: To select 100 students from a university with 10,000 students, you could assign each student a number from 1 to 10,000, then use a random number generator to select 100 numbers.\nStratified Random Sampling: The population is divided into subgroups (strata) based on shared characteristics, then samples are randomly selected from each stratum.\nExample: In a national political survey, you might divide the population into strata based on geographic regions (Northeast, Midwest, South, West) and then randomly sample from each region. This ensures representation from all areas of the country.\nCluster Sampling: The population is divided into clusters (usually geographic), some clusters are randomly selected, and all members within those clusters are studied.\nExample: To study high school students’ study habits, you might randomly select 20 high schools from across the country and then survey all students in those schools.\nSystematic Sampling: Selecting every kth item from a list after a random start.\nExample: At a busy shopping mall, you might survey every 20th person who enters the mall, starting with a randomly chosen number between 1 and 20.\n\n\n\n5.3.2 Non-probability Sampling\nNon-probability sampling doesn’t involve random selection. While it can introduce bias, it may be necessary in certain situations, especially when dealing with hard-to-reach populations or when resources are limited.\n\nConvenience Sampling: Selecting easily accessible subjects.\nExample: A researcher studying college students’ sleep patterns might survey students in their own classes or around campus.\nPurposive Sampling: Selecting subjects based on specific characteristics.\nExample: For a study on the experiences of CEOs in the tech industry, a researcher might intentionally seek out and interview CEOs from various tech companies.\nSnowball Sampling: Participants recruit other participants.\nExample: In a study of undocumented immigrants’ access to healthcare, researchers might ask initial participants to refer other potential participants from their community.\nQuota Sampling: Selecting participants to meet specific quotas for certain characteristics.\nExample: In a market research study, researchers might ensure they interview a specific number of people from different age groups, genders, and income levels to match the demographics of the target market.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#making-inferences-from-samples",
    "href": "chapter3.html#making-inferences-from-samples",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.4 Making Inferences from Samples",
    "text": "5.4 Making Inferences from Samples\nStatistical inference is the process of drawing conclusions about a population based on a sample. This allows researchers to estimate characteristics of the entire population (parameters) using characteristics of the sample (statistics).\nKey Concepts:\n\nPoint Estimates: A single value used to estimate a population parameter.\nExample: The mean income of a sample of 1000 workers might be used to estimate the mean income of all workers in a country.\nConfidence Intervals: A range of values likely to contain the true population parameter.\nExample: We might say, “We are 95% confident that the true population mean income falls between $45,000 and $55,000.”\nMargin of Error: The range of values above and below the sample statistic in a confidence interval.\nExample: In political polling, you might see a statement like “Candidate A is preferred by 52% of voters, with a margin of error of ±3%.”\nHypothesis Testing: A method for making decisions about population parameters based on sample data.\nExample: A researcher might test whether there’s a significant difference in test scores between students who study with music and those who study in silence.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#sampling-and-non-sampling-errors",
    "href": "chapter3.html#sampling-and-non-sampling-errors",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.5 Sampling and Non-sampling Errors",
    "text": "5.5 Sampling and Non-sampling Errors\nUnderstanding potential errors in research is crucial for interpreting results accurately.\nSampling Error: The difference between a sample statistic and the true population parameter, occurring due to chance variations in the selection of sample members.\nExample: If we estimate the average height of all adult males in a country based on a sample, our estimate will likely differ somewhat from the true average due to sampling error.\nNon-sampling Errors: Errors not due to chance, which can occur in both sample surveys and censuses.\n\nCoverage Error: When the sampling frame doesn’t accurately represent the population.\nExample: A telephone survey that only calls landlines would miss people who only have cell phones, potentially biasing the results.\nNon-response Error: When selected participants fail to respond, potentially introducing bias.\nExample: In a survey about job satisfaction, highly satisfied or highly dissatisfied employees might be more likely to respond, skewing the results.\nMeasurement Error: Inaccuracies in the data collected.\nExample: A poorly worded survey question might be interpreted differently by different respondents, leading to inconsistent data.\nProcessing Error: Mistakes made during data entry, coding, or analysis.\nExample: Accidentally entering “99” instead of “9” for a participant’s response could significantly skew the results.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#sample-size-and-power",
    "href": "chapter3.html#sample-size-and-power",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.6 Sample Size and Power",
    "text": "5.6 Sample Size and Power\nDetermining the appropriate sample size involves balancing the need for precision with available resources.\nSample Size Considerations: - Larger samples generally provide more precise estimates but are more costly and time-consuming to obtain. - The required sample size depends on factors such as the desired level of precision, the variability in the population, and the type of analysis planned.\nExample: To estimate the proportion of voters who support a particular policy with a margin of error of ±3% at a 95% confidence level, you would need a sample size of about 1067 voters (assuming maximum variability).\nStatistical Power: The probability that a study will detect an effect when there is an effect to be detected.\nFactors affecting power: 1. Sample size 2. Effect size (the magnitude of the difference or relationship you’re trying to detect) 3. Chosen significance level (usually 0.05)\nExample: In a study comparing two teaching methods, having a larger sample size would increase the likelihood of detecting a significant difference between the methods, if such a difference exists.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#sampling-in-the-digital-age",
    "href": "chapter3.html#sampling-in-the-digital-age",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.7 Sampling in the Digital Age",
    "text": "5.7 Sampling in the Digital Age\nThe advent of big data and digital technologies has transformed sampling practices in many fields.\nBig Data Opportunities and Challenges: - Unprecedented volumes of information available - Potential lack of representativeness - Data quality concerns - Privacy and ethical issues\nExample: Social media data can provide real-time insights into public opinion, but users of a particular platform may not be representative of the general population.\nWeb-based Surveys: - Offer new opportunities for data collection - Face challenges such as coverage bias (not everyone has internet access) and self-selection bias\nExample: An online survey about internet usage habits would inherently exclude people without internet access, potentially biasing the results.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#ethical-considerations-in-sampling",
    "href": "chapter3.html#ethical-considerations-in-sampling",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.8 Ethical Considerations in Sampling",
    "text": "5.8 Ethical Considerations in Sampling\nEthical sampling practices are crucial in social science research:\n\nInformed Consent: Participants should understand the study’s purpose and agree to participate.\nExample: Before conducting interviews about sensitive topics like mental health, researchers must clearly explain the study’s aims and potential risks to participants.\nPrivacy and Confidentiality: Researchers must protect participants’ personal information.\nExample: In a study on workplace harassment, researchers might use code numbers instead of names to protect participants’ identities.\nRepresentativeness and Inclusivity: Samples should fairly represent diverse populations, including marginalized groups.\nExample: A study on urban housing should make efforts to include participants from various socioeconomic backgrounds, ethnicities, and housing situations.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#case-studies",
    "href": "chapter3.html#case-studies",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.9 Case Studies",
    "text": "5.9 Case Studies\n[This section would include detailed examples of sampling in practice, such as: 1. How polling organizations predict election outcomes 2. How companies use market research to understand consumer preferences 3. How public health researchers study disease prevalence in populations]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#conclusion",
    "href": "chapter3.html#conclusion",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.10 Conclusion",
    "text": "5.10 Conclusion\nSampling remains a cornerstone of social science research, even in the era of big data. Understanding sampling principles helps researchers design studies, interpret results, and make valid inferences about populations. As we’ve seen, the journey from sample to population involves careful consideration of sampling methods, potential errors, ethical issues, and the ever-evolving landscape of data collection in the digital age.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#review-questions-and-exercises",
    "href": "chapter3.html#review-questions-and-exercises",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.11 Review Questions and Exercises",
    "text": "5.11 Review Questions and Exercises\n[This section would include a mix of multiple-choice questions, short answer prompts, and practical exercises to reinforce key concepts]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "chapter3.html#further-reading",
    "href": "chapter3.html#further-reading",
    "title": "5  From Sample to Population - Understanding Randomness, Sampling, and Inference",
    "section": "5.12 Further Reading",
    "text": "5.12 Further Reading\n[This section would list additional resources for students interested in deepening their understanding of sampling and related topics]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>From Sample to Population - Understanding Randomness, Sampling, and Inference</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html",
    "href": "rozdzial3.html",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "",
    "text": "6.1 Wprowadzenie do Losowości\nLosowość jest fundamentalnym pojęciem w statystyce i badaniach naukowych. Odnosi się do nieprzewidywalności indywidualnych wyników, nawet gdy ogólny wzorzec może być przewidywalny. W naukach społecznych zrozumienie losowości jest kluczowe dla projektowania badań, zbierania danych i interpretacji wyników.\nRozważmy rzut uczciwą monetą. Chociaż wiemy, że prawdopodobieństwo wypadnięcia orła wynosi 50%, nie możemy z pewnością przewidzieć wyniku pojedynczego rzutu. Ta nieprzewidywalność jest istotą losowości.\nPrzykłady losowych zjawisk w naukach społecznych obejmują:\nZrozumienie losowości pomaga badaczom odróżnić rzeczywiste efekty od przypadkowych zdarzeń. Na przykład, jeśli zaobserwujemy niewielką różnicę w wynikach testów między dwiema grupami, losowość pomaga nam określić, czy ta różnica jest prawdopodobnie spowodowana rzeczywistym efektem, czy tylko przypadkową zmiennością.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#wprowadzenie-do-losowości",
    "href": "rozdzial3.html#wprowadzenie-do-losowości",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "",
    "text": "Wybór uczestników: W eksperymencie psychologicznym badającym czasy reakcji, kolejność, w jakiej uczestnicy przybywają do laboratorium, może być losowa.\nZachowania ekonomiczne: Codzienne wahania cen akcji często wykazują losowe wzorce, na które wpływa niezliczona ilość nieprzewidywalnych czynników.\nInterakcje społeczne: Występowanie przypadkowych spotkań między osobami w społeczności można uznać za zdarzenia losowe.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#próbkowanie-łączenie-próby-i-populacji",
    "href": "rozdzial3.html#próbkowanie-łączenie-próby-i-populacji",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.2 Próbkowanie: Łączenie Próby i Populacji",
    "text": "6.2 Próbkowanie: Łączenie Próby i Populacji\nPróbkowanie to proces wybierania podzbioru (próby) z większej grupy (populacji) w celu wyciągnięcia wniosków o populacji. Jest to kluczowa umiejętność w badaniach nauk społecznych, ponieważ badanie całych populacji jest często niepraktyczne, zbyt kosztowne lub czasami niemożliwe.\nKluczowe pojęcia:\n\nPopulacja: Cała grupa, o której chcemy wyciągnąć wnioski.\nPróba: Podzbiór populacji, który faktycznie badamy.\nOperat losowania: Lista lub procedura używana do identyfikacji wszystkich członków populacji.\n\nPrzykład: Załóżmy, że chcemy zbadać satysfakcję z pracy wszystkich nauczycieli w Polsce (populacja). Zamiast ankietować setki tysięcy nauczycieli, możemy wybrać próbę 5000 nauczycieli z różnych województw, powiatów i poziomów nauczania.\nLosowość w próbkowaniu pomaga zapewnić, że próba jest reprezentatywna dla populacji, zmniejszając błędy systematyczne i umożliwiając dokładniejsze wnioskowanie. Dlatego metody próbkowania probabilistycznego, które omówimy dalej, są często preferowane w badaniach naukowych.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#metody-próbkowania",
    "href": "rozdzial3.html#metody-próbkowania",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.3 Metody Próbkowania",
    "text": "6.3 Metody Próbkowania\n\n6.3.1 Próbkowanie Probabilistyczne\nMetody próbkowania probabilistycznego obejmują losowy wybór, dając każdemu członkowi populacji znaną, niezerową szansę na wybór.\n\nProsty Dobór Losowy: Każdy członek populacji ma równą szansę na wybór.\nPrzykład: Aby wybrać 100 studentów z uniwersytetu liczącego 10 000 studentów, można przypisać każdemu studentowi numer od 1 do 10 000, a następnie użyć generatora liczb losowych do wybrania 100 numerów.\nDobór Losowy Warstwowy: Populacja jest podzielona na podgrupy (warstwy) na podstawie wspólnych cech, a następnie próbki są losowo wybierane z każdej warstwy.\nPrzykład: W ogólnopolskim badaniu politycznym można podzielić populację na warstwy na podstawie regionów geograficznych (np. Polska Zachodnia, Centralna, Wschodnia) i losowo pobierać próbki z każdego regionu. Zapewnia to reprezentację ze wszystkich obszarów kraju.\nDobór Losowy Grupowy: Populacja jest podzielona na skupiska (zwykle geograficzne), niektóre skupiska są losowo wybierane, a wszyscy członkowie w tych skupiskach są badani.\nPrzykład: Aby zbadać nawyki uczenia się uczniów szkół średnich, można losowo wybrać 20 szkół z całego kraju, a następnie przeprowadzić ankietę wśród wszystkich uczniów w tych szkołach.\nDobór Systematyczny: Wybieranie co k-tego elementu z listy po losowym starcie.\nPrzykład: W ruchliwym centrum handlowym można ankietować co 20. osobę wchodzącą do centrum, zaczynając od losowo wybranej liczby między 1 a 20.\n\n\n\n6.3.2 Próbkowanie Nieprobabilistyczne\nPróbkowanie nieprobabilistyczne nie obejmuje losowego wyboru. Chociaż może wprowadzać błędy systematyczne, może być konieczne w niektórych sytuacjach, zwłaszcza w przypadku trudno dostępnych populacji lub gdy zasoby są ograniczone.\n\nDobór Wygodny: Wybieranie łatwo dostępnych podmiotów.\nPrzykład: Badacz studiujący wzorce snu studentów może przeprowadzić ankietę wśród studentów na własnych zajęciach lub na terenie kampusu.\nDobór Celowy: Wybieranie podmiotów na podstawie określonych cech.\nPrzykład: W badaniu doświadczeń prezesów w branży technologicznej badacz może celowo szukać i przeprowadzać wywiady z prezesami różnych firm technologicznych.\nDobór Metodą Kuli Śnieżnej: Uczestnicy rekrutują innych uczestników.\nPrzykład: W badaniu dostępu imigrantów bez dokumentów do opieki zdrowotnej, badacze mogą poprosić początkowych uczestników o polecenie innych potencjalnych uczestników z ich społeczności.\nDobór Kwotowy: Wybieranie uczestników w celu spełnienia określonych kwot dla pewnych cech.\nPrzykład: W badaniu rynku badacze mogą zapewnić, że przeprowadzają wywiady z określoną liczbą osób z różnych grup wiekowych, płci i poziomów dochodów, aby dopasować się do demografii rynku docelowego.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#wnioskowanie-z-prób",
    "href": "rozdzial3.html#wnioskowanie-z-prób",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.4 Wnioskowanie z Prób",
    "text": "6.4 Wnioskowanie z Prób\nWnioskowanie statystyczne to proces wyciągania wniosków o populacji na podstawie próby. Pozwala to badaczom oszacować charakterystyki całej populacji (parametry) przy użyciu charakterystyk próby (statystyk).\nKluczowe pojęcia:\n\nEstymatory punktowe: Pojedyncza wartość używana do oszacowania parametru populacji.\nPrzykład: Średni dochód z próby 1000 pracowników może być użyty do oszacowania średniego dochodu wszystkich pracowników w kraju.\nPrzedziały ufności: Zakres wartości, który prawdopodobnie zawiera prawdziwy parametr populacji.\nPrzykład: Możemy powiedzieć: “Jesteśmy w 95% pewni, że prawdziwy średni dochód populacji mieści się między 4500 a 5500 złotych”.\nMargines błędu: Zakres wartości powyżej i poniżej statystyki próby w przedziale ufności.\nPrzykład: W sondażach politycznych można zobaczyć stwierdzenie: “Kandydat A jest preferowany przez 52% wyborców, z marginesem błędu ±3%”.\nTestowanie hipotez: Metoda podejmowania decyzji o parametrach populacji na podstawie danych z próby.\nPrzykład: Badacz może testować, czy istnieje istotna różnica w wynikach testów między uczniami, którzy uczą się przy muzyce, a tymi, którzy uczą się w ciszy.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#błędy-próbkowania-i-błędy-niepróbkowe",
    "href": "rozdzial3.html#błędy-próbkowania-i-błędy-niepróbkowe",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.5 Błędy Próbkowania i Błędy Niepróbkowe",
    "text": "6.5 Błędy Próbkowania i Błędy Niepróbkowe\nZrozumienie potencjalnych błędów w badaniach jest kluczowe dla dokładnej interpretacji wyników.\nBłąd próbkowania: Różnica między statystyką próby a prawdziwym parametrem populacji, występująca z powodu przypadkowych wahań w wyborze członków próby.\nPrzykład: Jeśli oszacujemy średni wzrost wszystkich dorosłych mężczyzn w kraju na podstawie próby, nasze oszacowanie prawdopodobnie będzie się nieco różnić od prawdziwej średniej z powodu błędu próbkowania.\nBłędy niepróbkowe: Błędy nie wynikające z przypadku, które mogą wystąpić zarówno w badaniach próbkowych, jak i spisach.\n\nBłąd pokrycia: Gdy operat losowania nie reprezentuje dokładnie populacji.\nPrzykład: Badanie telefoniczne, które dzwoni tylko na telefony stacjonarne, pominęłoby osoby posiadające tylko telefony komórkowe, potencjalnie wypaczając wyniki.\nBłąd braku odpowiedzi: Gdy wybrani uczestnicy nie odpowiadają, potencjalnie wprowadzając błąd systematyczny.\nPrzykład: W badaniu satysfakcji z pracy, bardzo zadowoleni lub bardzo niezadowoleni pracownicy mogą być bardziej skłonni do odpowiedzi, wypaczając wyniki.\nBłąd pomiaru: Niedokładności w zebranych danych.\nPrzykład: Źle sformułowane pytanie ankietowe może być różnie interpretowane przez różnych respondentów, prowadząc do niespójnych danych.\nBłąd przetwarzania: Błędy popełnione podczas wprowadzania danych, kodowania lub analizy.\nPrzykład: Przypadkowe wprowadzenie “99” zamiast “9” dla odpowiedzi uczestnika mogłoby znacząco wypaczyć wyniki.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#wielkość-próby-i-moc-statystyczna",
    "href": "rozdzial3.html#wielkość-próby-i-moc-statystyczna",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.6 Wielkość Próby i Moc Statystyczna",
    "text": "6.6 Wielkość Próby i Moc Statystyczna\nOkreślenie odpowiedniej wielkości próby wymaga zrównoważenia potrzeby precyzji z dostępnymi zasobami.\nRozważania dotyczące wielkości próby: - Większe próby generalnie zapewniają bardziej precyzyjne oszacowania, ale są bardziej kosztowne i czasochłonne do uzyskania. - Wymagana wielkość próby zależy od czynników takich jak pożądany poziom precyzji, zmienność w populacji i rodzaj planowanej analizy.\nPrzykład: Aby oszacować proporcję wyborców popierających konkretną politykę z marginesem błędu ±3% na poziomie ufności 95%, potrzebna byłaby próba około 1067 wyborców (zakładając maksymalną zmienność).\nMoc statystyczna: Prawdopodobieństwo, że badanie wykryje efekt, gdy taki efekt istnieje.\nCzynniki wpływające na moc: 1. Wielkość próby 2. Wielkość efektu (wielkość różnicy lub związku, który próbujemy wykryć) 3. Wybrany poziom istotności (zwykle 0,05)\nPrzykład: W badaniu porównującym dwie metody nauczania, większa wielkość próby zwiększyłaby prawdopodobieństwo wykrycia istotnej różnicy między metodami, jeśli taka różnica istnieje.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#próbkowanie-w-erze-cyfrowej",
    "href": "rozdzial3.html#próbkowanie-w-erze-cyfrowej",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.7 Próbkowanie w Erze Cyfrowej",
    "text": "6.7 Próbkowanie w Erze Cyfrowej\nPojawienie się big data i technologii cyfrowych zmieniło praktyki próbkowania w wielu dziedzinach.\nMożliwości i wyzwania Big Data: - Bezprecedensowe ilości dostępnych informacji - Potencjalny brak reprezentatywności - Problemy z jakością danych - Kwestie prywatności i etyki\nPrzykład: Dane z mediów społecznościowych mogą dostarczyć wglądu w opinię publiczną w czasie rzeczywistym, ale użytkownicy konkretnej platformy mogą nie być reprezentatywni dla ogólnej populacji.\nBadania internetowe: - Oferują nowe możliwości zbierania danych - Stają przed wyzwaniami takimi jak błąd pokrycia (nie każdy ma dostęp do internetu) i błąd samoselekcji\nPrzykład: Ankieta online na temat nawyków korzystania z internetu z natury wykluczałaby osoby bez dostępu do internetu, potencjalnie wypaczając wyniki.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#etyczne-aspekty-próbkowania",
    "href": "rozdzial3.html#etyczne-aspekty-próbkowania",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.8 Etyczne Aspekty Próbkowania",
    "text": "6.8 Etyczne Aspekty Próbkowania\nEtyczne praktyki próbkowania są kluczowe w badaniach nauk społecznych:\n\nŚwiadoma zgoda: Uczestnicy powinni rozumieć cel badania i zgodzić się na udział.\nPrzykład: Przed przeprowadzeniem wywiadów na temat wrażliwych tematów, takich jak zdrowie psychiczne, badacze muszą jasno wyjaśnić cele badania i potencjalne ryzyko uczestnikom.\nPrywatność i poufność: Badacze muszą chronić dane osobowe uczestników.\nPrzykład: W badaniu dotyczącym mobbingu w miejscu pracy, badacze mogą używać kodów numerycznych zamiast nazwisk, aby chronić tożsamość uczestników.\nReprezentatywność i inkluzywność: Próby powinny sprawiedliwie reprezentować zróżnicowane populacje, w tym grupy marginalizowane.\n\nPrzykład: Badanie dotyczące mieszkalnictwa miejskiego powinno dołożyć starań, aby uwzględnić uczestników z różnych środowisk społeczno-ekonomicznych, grup etnicznych i sytuacji mieszkaniowych.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#studia-przypadków",
    "href": "rozdzial3.html#studia-przypadków",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.9 Studia Przypadków",
    "text": "6.9 Studia Przypadków\n[Ta sekcja zawierałaby szczegółowe przykłady zastosowania próbkowania w praktyce, takie jak:]\n\nJak organizacje badania opinii publicznej przewidują wyniki wyborów\nPrzykład: Wyobraźmy sobie, że chcemy przewidzieć wynik wyborów prezydenckich w Polsce. Ośrodek badania opinii publicznej mógłby zastosować następującą metodologię:\n\nZastosowanie próbkowania warstwowego, dzieląc populację na warstwy według województw.\nLosowy wybór respondentów z każdej warstwy, proporcjonalnie do liczby mieszkańców.\nPrzeprowadzenie wywiadów telefonicznych z wybranymi osobami, pytając o ich preferencje wyborcze.\nWażenie wyników, aby skorygować ewentualne nadreprezentacje lub niedoreprezentacje pewnych grup demograficznych.\nObliczenie marginesu błędu i przedziałów ufności dla otrzymanych wyników.\n\nJak firmy wykorzystują badania rynku do zrozumienia preferencji konsumentów\nPrzykład: Firma produkująca napoje chce wprowadzić nowy smak na rynek polski. Mogłaby przeprowadzić badanie w następujący sposób:\n\nWykorzystanie próbkowania kwotowego, aby zapewnić reprezentację różnych grup wiekowych i regionów.\nOrganizacja degustacji w centrach handlowych w różnych miastach.\nPrzeprowadzenie ankiet online wśród członków panelu konsumenckiego.\nAnaliza danych z uwzględnieniem różnic demograficznych i geograficznych.\nWykorzystanie wyników do dostosowania produktu i strategii marketingowej.\n\nJak badacze zdrowia publicznego badają występowanie chorób w populacjach\nPrzykład: Badanie częstości występowania cukrzycy typu 2 w Polsce:\n\nZastosowanie próbkowania dwustopniowego: najpierw losowy wybór gmin, potem losowy wybór mieszkańców w tych gminach.\nPrzeprowadzenie badań przesiewowych wśród wybranych osób (pomiary poziomu cukru we krwi, BMI, itp.).\nZbieranie dodatkowych danych o stylu życia i historii medycznej.\nAnaliza danych z uwzględnieniem czynników demograficznych i środowiskowych.\nOszacowanie częstości występowania cukrzycy w całej populacji na podstawie wyników próby.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#podsumowanie",
    "href": "rozdzial3.html#podsumowanie",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.10 Podsumowanie",
    "text": "6.10 Podsumowanie\nPróbkowanie pozostaje fundamentem badań w naukach społecznych, nawet w erze big data. Zrozumienie zasad próbkowania pomaga badaczom projektować badania, interpretować wyniki i wyciągać trafne wnioski o populacjach. Jak widzieliśmy, droga od próby do populacji wymaga starannego rozważenia metod próbkowania, potencjalnych błędów, kwestii etycznych i stale ewoluującego krajobrazu gromadzenia danych w erze cyfrowej.\nKluczowe punkty do zapamiętania:\n\nLosowość jest podstawą wielu metod próbkowania i pomaga zapewnić reprezentatywność próby.\nIstnieją różne metody próbkowania, zarówno probabilistyczne, jak i nieprobabilistyczne, każda z własnymi zaletami i ograniczeniami.\nWnioskowanie statystyczne pozwala nam wyciągać wnioski o populacji na podstawie danych z próby.\nBłędy próbkowania i niepróbkowe mogą wpływać na jakość naszych wniosków, dlatego ważne jest ich zrozumienie i minimalizowanie.\nWielkość próby i moc statystyczna są kluczowe dla zapewnienia wiarygodności wyników badań.\nEra cyfrowa przynosi nowe możliwości i wyzwania w zakresie próbkowania i gromadzenia danych.\nEtyczne aspekty próbkowania, w tym świadoma zgoda, prywatność i reprezentatywność, są nieodłączną częścią procesu badawczego.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#pytania-kontrolne-i-ćwiczenia",
    "href": "rozdzial3.html#pytania-kontrolne-i-ćwiczenia",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.11 Pytania Kontrolne i Ćwiczenia",
    "text": "6.11 Pytania Kontrolne i Ćwiczenia\n\nJakie są główne różnice między próbkowaniem probabilistycznym a nieprobabilistycznym? Podaj przykłady sytuacji, w których każde z nich mogłoby być odpowiednie.\nWyobraź sobie, że prowadzisz badanie dotyczące opinii studentów na temat nauczania zdalnego. Zaproponuj odpowiednią metodę próbkowania i uzasadnij swój wybór.\nJakie potencjalne błędy próbkowania i niepróbkowe mogłyby wystąpić w badaniu opisanym w pytaniu 2? Jak można by je zminimalizować?\nOblicz wymaganą wielkość próby dla badania opinii publicznej, zakładając poziom ufności 95%, margines błędu 3% i maksymalną zmienność (p = 0,5).\nOmów etyczne aspekty próbkowania w kontekście badania wrażliwych grup społecznych, takich jak osoby bezdomne lub nieletni.\nJak era big data wpływa na tradycyjne metody próbkowania? Omów zarówno możliwości, jak i wyzwania.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "rozdzial3.html#dalsza-lektura",
    "href": "rozdzial3.html#dalsza-lektura",
    "title": "6  Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania",
    "section": "6.12 Dalsza Lektura",
    "text": "6.12 Dalsza Lektura\n\nBabbie, E. (2020). “Badania społeczne w praktyce”. Warszawa: Wydawnictwo Naukowe PWN.\nFrankfort-Nachmias, C., & Nachmias, D. (2001). “Metody badawcze w naukach społecznych”. Poznań: Zysk i S-ka.\nGruszczyński, L. A. (2003). “Kwestionariusze w socjologii: budowa narzędzi do badań surveyowych”. Katowice: Wydawnictwo Uniwersytetu Śląskiego.\nSzreder, M. (2010). “Metody i techniki sondażowych badań opinii”. Warszawa: Polskie Wydawnictwo Ekonomiczne.\nBrzeziński, J. (2019). “Metodologia badań psychologicznych”. Warszawa: Wydawnictwo Naukowe PWN.\n\nTe źródła zapewniają dogłębne omówienie tematów związanych z próbkowaniem i metodologią badań w naukach społecznych w kontekście polskim.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Od Próby do Populacji - Zrozumienie Losowości, Próbkowania i Wnioskowania</span>"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "9  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "",
    "text": "9.1 Introduction\nResearch designs are fundamental to the scientific process, providing structured approaches to investigate hypotheses and answer research questions. This chapter explores two main categories of research designs: experimental and non-experimental, with a focus on the Neyman-Rubin potential outcome framework. We’ll delve into various design types, their characteristics, and provide practical examples using R for data analysis and visualization.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#introduction-to-validity-reliability-and-related-concepts",
    "href": "chapter4.html#introduction-to-validity-reliability-and-related-concepts",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "",
    "text": "7.1.1 Validity\nValidity refers to the extent to which a measurement or study accurately reflects or assesses the specific concept that the researcher is attempting to measure.\nTypes of Validity: - Internal Validity: The extent to which a study establishes a causal relationship between the independent and dependent variables. - External Validity: The extent to which the results of a study can be generalized to other situations and to other people. - Construct Validity: The extent to which a test measures the concept or construct that it is intended to measure. - Content Validity: The extent to which a measure represents all facets of a given construct.\n\n\n7.1.2 Reliability\nReliability refers to the consistency of a measure. A measurement is considered reliable if it produces similar results under consistent conditions.\nTypes of Reliability: - Test-Retest Reliability: The degree to which test scores are consistent from one test administration to the next. - Inter-Rater Reliability: The degree of agreement among raters. - Internal Consistency: The consistency of results across items within a test.\n\n\n7.1.3 Bias, Variance, Accuracy, and Precision\nThese concepts are often used in discussions of measurement and study design, and some overlap in their meanings:\n\nBias: A systematic error that leads to a deviation from the true value. Bias can occur in sampling, measurement, or analysis.\nVariance: The spread of data points around the mean. Low variance indicates that data points are clustered closely around the mean.\nAccuracy: The closeness of a measured value to the actual (true) value. Accuracy is affected by both bias and variance.\nPrecision: The closeness of two or more measurements to each other. Precision is related to reliability and is affected by random error.\n\nLet’s visualize these concepts using R:\n\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Function to generate data\ngenerate_data &lt;- function(n, true_mean, bias, sd) {\n  data &lt;- rnorm(n, mean = true_mean + bias, sd = sd)\n  return(data)\n}\n\n# Generate datasets\nset.seed(123)\naccurate_precise &lt;- generate_data(100, 10, 0, 1)\nbiased_precise &lt;- generate_data(100, 10, 2, 1)\naccurate_imprecise &lt;- generate_data(100, 10, 0, 3)\nbiased_imprecise &lt;- generate_data(100, 10, 2, 3)\n\n# Create plots\nplot_data &lt;- function(data, title) {\n  ggplot(data.frame(x = data), aes(x = x)) +\n    geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +\n    geom_vline(xintercept = 10, color = \"red\", linetype = \"dashed\") +\n    xlim(0, 20) +\n    ggtitle(title) +\n    theme_minimal()\n}\n\np1 &lt;- plot_data(accurate_precise, \"Accurate & Precise\")\np2 &lt;- plot_data(biased_precise, \"Biased but Precise\")\np3 &lt;- plot_data(accurate_imprecise, \"Accurate but Imprecise\")\np4 &lt;- plot_data(biased_imprecise, \"Biased & Imprecise\")\n\n# Combine plots\ngrid.arrange(p1, p2, p3, p4, ncol = 2)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nThis R code generates four plots illustrating different combinations of accuracy and precision. The red dashed line represents the true value.\nUnderstanding these concepts is crucial for evaluating the quality of research and interpreting results.\n\n\n7.1.4 Bias, Variance, Accuracy, and Precision: Relation to Validity and Reliability\nThese concepts are often used in discussions of measurement and study design, and they have important relationships with validity and reliability:\n\nBias: A systematic error that leads to a deviation from the true value. Bias can occur in sampling, measurement, or analysis. Bias is closely related to validity, particularly construct validity. A biased measure or study design threatens the validity of the research by systematically misrepresenting the concept being studied.\nVariance: The spread of data points around the mean. Low variance indicates that data points are clustered closely around the mean. Variance is related to reliability; high variance in repeated measurements suggests low reliability.\nAccuracy: The closeness of a measured value to the actual (true) value. Accuracy is affected by both bias and variance. Accuracy is closely tied to validity – an accurate measure is more likely to be valid, as it correctly represents the true value of what’s being measured.\nPrecision: The closeness of two or more measurements to each other. Precision is related to reliability and is affected by random error. A precise measure will give consistent results over repeated trials, which is a key aspect of reliability.\n\nThe relationships between these concepts can be summarized as follows:\n\nValidity and Accuracy: A valid measure is one that accurately measures what it’s supposed to measure. An accurate measure contributes to the validity of a study by correctly representing the concept being studied.\nReliability and Precision: A reliable measure is one that consistently produces similar results under similar conditions. Precision contributes to reliability by ensuring that repeated measurements are close to each other.\nBias and Validity: Bias threatens validity by systematically skewing results away from the true value. Reducing bias improves the validity of a study.\nVariance and Reliability: High variance can indicate low reliability, as it suggests inconsistency in measurements. Reducing variance (while maintaining accuracy) can improve reliability.\nAccuracy, Precision, and Overall Quality: A high-quality measure or study design aims to be both accurate (low bias) and precise (low variance). This contributes to both validity and reliability.\n\nLet’s visualize these concepts using R:\n\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Function to generate data\ngenerate_data &lt;- function(n, true_mean, bias, sd) {\n  data &lt;- rnorm(n, mean = true_mean + bias, sd = sd)\n  return(data)\n}\n\n# Generate datasets\nset.seed(123)\naccurate_precise &lt;- generate_data(100, 10, 0, 1)\nbiased_precise &lt;- generate_data(100, 10, 2, 1)\naccurate_imprecise &lt;- generate_data(100, 10, 0, 3)\nbiased_imprecise &lt;- generate_data(100, 10, 2, 3)\n\n# Create plots\nplot_data &lt;- function(data, title) {\n  ggplot(data.frame(x = data), aes(x = x)) +\n    geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +\n    geom_vline(xintercept = 10, color = \"red\", linetype = \"dashed\") +\n    xlim(0, 20) +\n    ggtitle(title) +\n    theme_minimal() +\n    annotate(\"text\", x = 10, y = 20, label = \"True Value\", color = \"red\", hjust = -0.1)\n}\n\np1 &lt;- plot_data(accurate_precise, \"Valid & Reliable\\n(Accurate & Precise)\")\np2 &lt;- plot_data(biased_precise, \"Not Valid, but Reliable\\n(Biased but Precise)\")\np3 &lt;- plot_data(accurate_imprecise, \"Valid, but Not Reliable\\n(Accurate but Imprecise)\")\np4 &lt;- plot_data(biased_imprecise, \"Neither Valid nor Reliable\\n(Biased & Imprecise)\")\n\n# Combine plots\ngrid.arrange(p1, p2, p3, p4, ncol = 2)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nThis R code generates four plots illustrating different combinations of validity (accuracy) and reliability (precision). The red dashed line represents the true value.\n\nValid & Reliable (Accurate & Precise): Low bias, low variance\nNot Valid, but Reliable (Biased but Precise): High bias, low variance\nValid, but Not Reliable (Accurate but Imprecise): Low bias, high variance\nNeither Valid nor Reliable (Biased & Imprecise): High bias, high variance\n\nUnderstanding these relationships is crucial for evaluating the quality of research methods and interpreting results. Researchers strive to develop measures and study designs that are both valid (accurate, unbiased) and reliable (precise, consistent), thereby ensuring the overall quality and trustworthiness of their findings.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter4.html#introduction-to-study-types",
    "href": "chapter4.html#introduction-to-study-types",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "7.2 Introduction to Study Types",
    "text": "7.2 Introduction to Study Types\nIn social sciences, researchers use various study designs to investigate phenomena, test hypotheses, and draw conclusions. The choice of study type depends on the research question, available resources, and ethical considerations. This chapter will explore three main categories of study types:\n\nExperimental Design\nNon-Experimental: Observational Studies\nQuasi-Experimental Design\n\nWe’ll pay special attention to modern quasi-experimental methods that allow for causal reasoning.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter4.html#experimental-design",
    "href": "chapter4.html#experimental-design",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "7.3 Experimental Design",
    "text": "7.3 Experimental Design\n\n7.3.1 Key Features\n\nRandom assignment of participants to treatment and control groups\nManipulation of independent variable(s)\nControl of extraneous variables\n\n\n\n7.3.2 Strengths\n\nAllows for causal inference\nHigh internal validity\n\n\n\n7.3.3 Limitations\n\nMay lack external validity (generalizability)\nEthical constraints in some situations\nCan be resource-intensive\n\n\n\n7.3.4 Example: The Effect of Social Media Use on Self-Esteem\nResearch Question: Does increased social media use lead to lower self-esteem in teenagers?\nMethod: - Randomly assign 200 teenagers to two groups: - Treatment group: Required to use social media for 3 hours daily - Control group: Asked to refrain from social media use - Duration: 4 weeks - Measure self-esteem before and after the experiment using a validated scale\nAnalysis: Compare the change in self-esteem scores between the two groups using a t-test or ANOVA.\nLet’s visualize this using R:\n\nlibrary(ggplot2)\n\n# Generating example data\nset.seed(123)\nn &lt;- 100\npre_treatment &lt;- rnorm(n, mean = 50, sd = 10)\npost_treatment &lt;- pre_treatment + rnorm(n, mean = -5, sd = 5)\npre_control &lt;- rnorm(n, mean = 50, sd = 10)\npost_control &lt;- pre_control + rnorm(n, mean = 0, sd = 5)\n\ndata &lt;- data.frame(\n  Group = rep(c(\"Treatment\", \"Control\"), each = n*2),\n  Time = rep(rep(c(\"Pre\", \"Post\"), each = n), 2),\n  Score = c(pre_treatment, post_treatment, \n            pre_control, post_control)\n)\n\n# Creating the plot\nggplot(data, aes(x = Time, y = Score, color = Group, group = Group)) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Effect of Social Media Use on Self-Esteem\") +\n  xlab(\"Time\") +\n  ylab(\"Self-Esteem Score\")\n\n\n\n\n\n\n\nFigure 7.1: Effect of social media use on self-esteem\n\n\n\n\n\nThis plot shows the pre- and post-test scores for both the treatment and control groups, illustrating the potential effect of increased social media use on self-esteem.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter4.html#non-experimental-observational-studies",
    "href": "chapter4.html#non-experimental-observational-studies",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "7.4 Non-Experimental: Observational Studies",
    "text": "7.4 Non-Experimental: Observational Studies\n\n7.4.1 Key Features\n\nNo manipulation of variables\nSubjects are observed in their natural settings\nCan be cross-sectional or longitudinal\n\n\n\n7.4.2 Strengths\n\nHigh external validity\nSuitable for studying phenomena that can’t be manipulated\nOften more feasible and ethical than experiments\n\n\n\n7.4.3 Limitations\n\nCannot establish causality\nSusceptible to confounding variables\n\n\n\n7.4.4 Example: The Relationship Between Education Level and Income\nResearch Question: Is there a correlation between education level and income?\nMethod: - Collect data on education level and income from a large, representative sample - Use surveys or existing datasets (e.g., census data)\nAnalysis: Calculate the correlation coefficient or use regression analysis to examine the relationship between education level and income.\nLet’s visualize this relationship using R:\n\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Generate example data\nset.seed(123)\nn &lt;- 1000\neducation &lt;- sample(c(\"High School\", \"Bachelor's\", \"Master's\", \"PhD\"), n, replace = TRUE, prob = c(0.4, 0.3, 0.2, 0.1))\nincome &lt;- case_when(\n  education == \"High School\" ~ rnorm(n, 30000, 5000),\n  education == \"Bachelor's\" ~ rnorm(n, 50000, 10000),\n  education == \"Master's\" ~ rnorm(n, 70000, 15000),\n  education == \"PhD\" ~ rnorm(n, 90000, 20000)\n)\n\ndata &lt;- data.frame(Education = education, Income = income)\n\n# Create plot\nggplot(data, aes(x = Education, y = Income)) +\n  geom_boxplot(fill = \"skyblue\") +\n  geom_jitter(width = 0.2, alpha = 0.2) +\n  theme_minimal() +\n  ggtitle(\"Relationship Between Education Level and Income\")\n\n\n\n\n\n\n\n\nThis boxplot shows the distribution of income for different education levels, illustrating the potential relationship between education and income.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter4.html#quasi-experimental-design",
    "href": "chapter4.html#quasi-experimental-design",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "7.5 Quasi-Experimental Design",
    "text": "7.5 Quasi-Experimental Design\n\n7.5.1 Key Features\n\nLacks random assignment\nAttempts to establish causality in real-world settings\nOften uses naturally occurring events or policy changes\n\n\n\n7.5.2 Strengths\n\nCan suggest causal relationships\nOften more feasible than true experiments\nHigher external validity than true experiments\n\n\n\n7.5.3 Limitations\n\nLower internal validity than true experiments\nPotential for selection bias\n\n\n\n7.5.4 Modern Quasi-Experimental Methods\n\n7.5.4.1 Difference-in-Differences (DiD)\nKey Concept: Compares the change in outcomes over time between a group affected by a treatment (or policy change) and a group not affected.\nExample: The Impact of Minimum Wage Increase on Employment\nResearch Question: Does increasing the minimum wage reduce employment?\nMethod: - Treatment group: State A increases minimum wage - Control group: Neighboring State B keeps minimum wage constant - Measure employment rates before and after the policy change in both states\nAnalysis: 1. Calculate the difference in employment rates before and after for each state 2. Compare the difference between these differences\nDiD = (Treatment_After - Treatment_Before) - (Control_After - Control_Before)\nLet’s visualize this using R:\n\nlibrary(ggplot2)\n\n# Generate example data\nset.seed(123)\ntime &lt;- rep(c(\"Before\", \"After\"), each = 100)\nstate &lt;- rep(c(\"State A (Treatment)\", \"State B (Control)\"), each = 50, times = 2)\nemployment_rate &lt;- c(\n  rnorm(50, 0.6, 0.05), rnorm(50, 0.61, 0.05),  # State A Before\n  rnorm(50, 0.59, 0.05), rnorm(50, 0.62, 0.05), # State B Before\n  rnorm(50, 0.58, 0.05), rnorm(50, 0.59, 0.05), # State A After (decreased)\n  rnorm(50, 0.61, 0.05), rnorm(50, 0.64, 0.05)  # State B After (increased)\n)\n\ndata &lt;- data.frame(Time = time, State = state, EmploymentRate = employment_rate)\n\n# Create plot\nggplot(data, aes(x = Time, y = EmploymentRate, color = State, group = State)) +\n  geom_point(position = position_jitter(width = 0.1), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Difference-in-Differences: Impact of Minimum Wage on Employment\")\n\n\n\n\n\n\n\n\nThis plot illustrates the Difference-in-Differences approach, showing the change in employment rates for both the treatment and control states before and after the policy change.\n\n\n7.5.4.2 Regression Discontinuity Design (RDD)\nKey Concept: Exploits a threshold or cutoff point in a continuous variable to assign subjects to treatment or control groups.\nExample: The Effect of Financial Aid on College Enrollment\nResearch Question: Does receiving financial aid increase college enrollment?\nMethod: - Identify a cutoff point in a continuous variable (e.g., family income) that determines aid eligibility - Compare outcomes for individuals just above and below the cutoff\nAnalysis: - Use regression analysis to estimate the treatment effect at the cutoff point\nLet’s visualize this using R:\n\nlibrary(ggplot2)\n\n# Generate example data\nset.seed(123)\nn &lt;- 1000\nfamily_income &lt;- runif(n, 20000, 80000)\ncutoff &lt;- 50000\neligible &lt;- family_income &lt;= cutoff\nenrollment &lt;- ifelse(eligible, \n                     rbinom(n, 1, plogis(-5 + 0.00015 * family_income + 0.5)),\n                     rbinom(n, 1, plogis(-5 + 0.00015 * family_income)))\n\ndata &lt;- data.frame(FamilyIncome = family_income, Enrollment = enrollment, Eligible = eligible)\n\n# Create plot\nggplot(data, aes(x = FamilyIncome, y = Enrollment)) +\n  geom_point(aes(color = Eligible), alpha = 0.5) +\n  geom_vline(xintercept = cutoff, linetype = \"dashed\") +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  scale_color_manual(values = c(\"red\", \"blue\")) +\n  theme_minimal() +\n  ggtitle(\"Regression Discontinuity: Effect of Financial Aid on Enrollment\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis plot demonstrates the Regression Discontinuity Design, showing the relationship between family income and college enrollment, with a clear discontinuity at the financial aid eligibility cutoff.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter4.html#choosing-the-appropriate-study-type",
    "href": "chapter4.html#choosing-the-appropriate-study-type",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "7.6 Choosing the Appropriate Study Type",
    "text": "7.6 Choosing the Appropriate Study Type\nWhen selecting a study type, consider:\n\nResearch question and hypotheses\nEthical considerations\nAvailable resources (time, budget, access to participants)\nDesired level of causal inference\nExternal validity requirements",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter4.html#conclusion",
    "href": "chapter4.html#conclusion",
    "title": "9  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "9.6 Conclusion",
    "text": "9.6 Conclusion\nThis chapter has explored various research designs, from experimental approaches like RCTs and factorial designs to non-experimental methods such as observational studies and quasi-experimental designs. We’ve demonstrated how to implement and visualize these designs using R, and introduced the Neyman-Rubin potential outcome framework for causal inference.\nUnderstanding these designs and their appropriate use is crucial for conducting rigorous research and drawing valid causal conclusions. Each design has its strengths and limitations, and the choice of design should be guided by the research question, ethical considerations, and practical constraints.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#review-questions",
    "href": "chapter4.html#review-questions",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "7.8 Review Questions",
    "text": "7.8 Review Questions\n\nExplain the differences between validity and reliability. How do these concepts relate to bias and precision?\nWhat are the key differences between experimental, quasi-experimental, and observational studies?\nIn what situations might a researcher choose a quasi-experimental design over a true experiment?\nExplain the concept of Difference-in-Differences. What are its key assumptions?\nHow does Regression Discontinuity Design allow for causal inference?\nDesign a hypothetical study using one of the methods discussed in this chapter to investigate a social science question of your choice.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter4.html#further-reading",
    "href": "chapter4.html#further-reading",
    "title": "7  Validity, Reliability, and Study Types in Social Sciences",
    "section": "7.9 Further Reading",
    "text": "7.9 Further Reading\n\nShadish, W. R., Cook, T. D., & Campbell, D. T. (2002). Experimental and Quasi-experimental Designs for Generalized Causal Inference. Houghton Mifflin.\nAngrist, J. D., & Pischke, J. S. (2014). Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\nCunningham, S. (2021). Causal Inference: The Mixtape. Yale University Press.\nImbens, G. W., & Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html",
    "href": "rozdzial4.html",
    "title": "8  Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne",
    "section": "",
    "text": "8.1 Wstęp\nProjekty badawcze stanowią fundament procesu naukowego, zapewniając ustrukturyzowane podejście do badania hipotez i odpowiadania na pytania badawcze. Ten rozdział analizuje dwie główne kategorie projektów badawczych: eksperymentalne i nieeksperymentalne, ze szczególnym uwzględnieniem modelu potencjalnych wyników Neymana-Rubina. Zagłębimy się w różne typy projektów, ich charakterystykę i przedstawimy praktyczne przykłady wykorzystania R do analizy danych i wizualizacji.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#wprowadzenie-do-trafności-rzetelności-i-powiązanych-pojęć",
    "href": "rozdzial4.html#wprowadzenie-do-trafności-rzetelności-i-powiązanych-pojęć",
    "title": "8  Trafność, Rzetelność i Typy Badań w Naukach Społecznych",
    "section": "",
    "text": "8.1.1 Trafność\nTrafność odnosi się do stopnia, w jakim pomiar lub badanie dokładnie odzwierciedla lub ocenia konkretną koncepcję, którą badacz próbuje zmierzyć.\nTypy Trafności:\n\nTrafność Wewnętrzna: Stopień, w jakim badanie ustanawia związek przyczynowy między zmiennymi niezależnymi a zależnymi.\nTrafność Zewnętrzna: Stopień, w jakim wyniki badania można uogólnić na inne sytuacje i inne osoby.\nTrafność Konstruktu: Stopień, w jakim test mierzy pojęcie lub konstrukt, który ma mierzyć.\nTrafność Treściowa: Stopień, w jakim pomiar reprezentuje wszystkie aspekty danego konstruktu.\n\n\n\n8.1.2 Rzetelność\nRzetelność odnosi się do spójności pomiaru. Pomiar jest uważany za rzetelny, jeśli daje podobne wyniki w spójnych warunkach.\nTypy Rzetelności:\n\nRzetelność Test-Retest: Stopień, w jakim wyniki testu są spójne między jednym a drugim podejściem do testu.\nRzetelność Międzyoceniająca: Stopień zgodności między oceniającymi.\nSpójność Wewnętrzna: Spójność wyników między pozycjami w ramach testu.\n\n\n\n8.1.3 Błąd Systematyczny, Wariancja, Dokładność i Precyzja: Związek z Trafnością i Rzetelnością\nTe pojęcia są często używane w dyskusjach o pomiarze i projektowaniu badań i mają ważne związki z trafnością i rzetelnością:\n\nBłąd Systematyczny: Systematyczny błąd prowadzący do odchylenia od prawdziwej wartości. Jest ściśle związany z trafnością, szczególnie trafnością konstruktu.\nWariancja: Rozrzut punktów danych wokół średniej. Wariancja jest związana z rzetelnością; wysoka wariancja w powtarzanych pomiarach sugeruje niską rzetelność.\nDokładność: Bliskość zmierzonej wartości do rzeczywistej wartości. Jest ściśle powiązana z trafnością.\nPrecyzja: Bliskość dwóch lub więcej pomiarów względem siebie. Precyzja jest związana z rzetelnością.\n\nZobrazujmy te pojęcia za pomocą R:\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Funkcja do generowania danych\ngeneruj_dane &lt;- function(n, prawdziwa_srednia, blad, sd) {\n  dane &lt;- rnorm(n, mean = prawdziwa_srednia + blad, sd = sd)\n  return(dane)\n}\n\n# Generowanie zbiorów danych\nset.seed(123)\ndokladne_precyzyjne &lt;- generuj_dane(100, 10, 0, 1)\nobciazene_precyzyjne &lt;- generuj_dane(100, 10, 2, 1)\ndokladne_nieprecyzyjne &lt;- generuj_dane(100, 10, 0, 3)\nobciazene_nieprecyzyjne &lt;- generuj_dane(100, 10, 2, 3)\n\n# Tworzenie wykresów\nrysuj_wykres &lt;- function(dane, tytul) {\n  ggplot(data.frame(x = dane), aes(x = x)) +\n    geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +\n    geom_vline(xintercept = 10, color = \"red\", linetype = \"dashed\") +\n    xlim(0, 20) +\n    ggtitle(tytul) +\n    theme_minimal() +\n    annotate(\"text\", x = 10, y = 20, label = \"Prawdziwa Wartość\", color = \"red\", hjust = -0.1)\n}\n\np1 &lt;- rysuj_wykres(dokladne_precyzyjne, \"Trafne i Rzetelne\\n(Dokładne i Precyzyjne)\")\np2 &lt;- rysuj_wykres(obciazene_precyzyjne, \"Nietrafne, ale Rzetelne\\n(Obciążone, ale Precyzyjne)\")\np3 &lt;- rysuj_wykres(dokladne_nieprecyzyjne, \"Trafne, ale Nierzetelne\\n(Dokładne, ale Nieprecyzyjne)\")\np4 &lt;- rysuj_wykres(obciazene_nieprecyzyjne, \"Ani Trafne, ani Rzetelne\\n(Obciążone i Nieprecyzyjne)\")\n\n# Łączenie wykresów\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\n\nFigure 8.1: Ilustracja trafności i rzetelności\n\n\n\n\n\nPowyższy wykres ilustruje różne kombinacje trafności (dokładności) i rzetelności (precyzji). Czerwona przerywana linia reprezentuje prawdziwą wartość.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#typy-badań-w-naukach-społecznych",
    "href": "rozdzial4.html#typy-badań-w-naukach-społecznych",
    "title": "8  Trafność, Rzetelność i Typy Badań w Naukach Społecznych",
    "section": "8.2 Typy Badań w Naukach Społecznych",
    "text": "8.2 Typy Badań w Naukach Społecznych\nW naukach społecznych badacze wykorzystują różne projekty badań do badania zjawisk, testowania hipotez i wyciągania wniosków. Ten rozdział omówi trzy główne kategorie typów badań:\n\nBadania Eksperymentalne\nBadania Nieeksperymentalne: Badania Obserwacyjne\nBadania Quasi-eksperymentalne\n\n\n8.2.1 Badania Eksperymentalne\nKluczowe cechy badań eksperymentalnych:\n\nLosowy przydział uczestników do grup\nManipulacja zmienną(ymi) niezależną(ymi)\nKontrola zmiennych zakłócających\n\n\n8.2.1.1 Przykład: Wpływ Korzystania z Mediów Społecznościowych na Samoocenę\nPytanie Badawcze: Czy zwiększone korzystanie z mediów społecznościowych prowadzi do niższej samooceny u nastolatków?\n\n# Generowanie przykładowych danych\nset.seed(123)\nn &lt;- 100\nprzed_eksperymentalna &lt;- rnorm(n, mean = 50, sd = 10)\npo_eksperymentalna &lt;- przed_eksperymentalna + rnorm(n, mean = -5, sd = 5)\nprzed_kontrolna &lt;- rnorm(n, mean = 50, sd = 10)\npo_kontrolna &lt;- przed_kontrolna + rnorm(n, mean = 0, sd = 5)\n\ndane &lt;- data.frame(\n  Grupa = rep(c(\"Eksperymentalna\", \"Kontrolna\"), each = n*2),\n  Czas = rep(rep(c(\"Przed\", \"Po\"), each = n), 2),\n  Wynik = c(przed_eksperymentalna, po_eksperymentalna, \n            przed_kontrolna, po_kontrolna)\n)\n\n# Tworzenie wykresu\nggplot(dane, aes(x = Czas, y = Wynik, color = Grupa, group = Grupa)) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Wpływ Korzystania z Mediów Społecznościowych na Samoocenę\") +\n  xlab(\"Czas\") +\n  ylab(\"Wynik Samooceny\")\n\n\n\n\n\n\n\nFigure 8.2: Wpływ korzystania z mediów społecznościowych na samoocenę\n\n\n\n\n\n\n\n\n8.2.2 Badania Nieeksperymentalne: Badania Obserwacyjne\nKluczowe cechy badań obserwacyjnych:\n\nBrak manipulacji zmiennymi\nPodmioty są obserwowane w ich naturalnym środowisku\nMogą być przekrojowe lub podłużne\n\n\n8.2.2.1 Przykład: Związek Między Poziomem Wykształcenia a Dochodem\nPytanie Badawcze: Czy istnieje korelacja między poziomem wykształcenia a dochodem?\n\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n# Generowanie przykładowych danych\nset.seed(123)\nn &lt;- 1000\nwyksztalcenie &lt;- sample(c(\"Średnie\", \"Licencjat\", \"Magister\", \"Doktorat\"), n, replace = TRUE, prob = c(0.4, 0.3, 0.2, 0.1))\ndochod &lt;- case_when(\n  wyksztalcenie == \"Średnie\" ~ rnorm(n, 3000, 500),\n  wyksztalcenie == \"Licencjat\" ~ rnorm(n, 5000, 1000),\n  wyksztalcenie == \"Magister\" ~ rnorm(n, 7000, 1500),\n  wyksztalcenie == \"Doktorat\" ~ rnorm(n, 9000, 2000)\n)\n\ndane &lt;- data.frame(Wyksztalcenie = wyksztalcenie, Dochod = dochod)\n\n# Tworzenie wykresu\nggplot(dane, aes(x = Wyksztalcenie, y = Dochod)) +\n  geom_boxplot(fill = \"skyblue\") +\n  geom_jitter(width = 0.2, alpha = 0.2) +\n  theme_minimal() +\n  ggtitle(\"Związek Między Poziomem Wykształcenia a Dochodem\") +\n  xlab(\"Poziom Wykształcenia\") +\n  ylab(\"Dochód (PLN)\")\n\n\n\n\n\n\n\nFigure 8.3: Związek między poziomem wykształcenia a dochodem\n\n\n\n\n\n\n\n\n8.2.3 Badania Quasi-eksperymentalne\nBadania quasi-eksperymentalne łączą cechy badań eksperymentalnych i obserwacyjnych. Często wykorzystują naturalne eksperymenty lub zmiany polityk do badania związków przyczynowych.\n\n8.2.3.1 Przykład: Metoda Różnicy w Różnicach (DiD)\nPytanie Badawcze: Czy podniesienie płacy minimalnej wpływa na poziom zatrudnienia?\n\nlibrary(ggplot2)\n\n# Generowanie przykładowych danych\nset.seed(123)\nczas &lt;- rep(c(\"Przed\", \"Po\"), each = 100)\nwojewodztwo &lt;- rep(c(\"Woj. A (Eksperymentalne)\", \"Woj. B (Kontrolne)\"), each = 50, times = 2)\nstopa_zatrudnienia &lt;- c(\n  rnorm(50, 0.6, 0.05), rnorm(50, 0.61, 0.05),  # Woj. A Przed\n  rnorm(50, 0.59, 0.05), rnorm(50, 0.62, 0.05), # Woj. B Przed\n  rnorm(50, 0.58, 0.05), rnorm(50, 0.59, 0.05), # Woj. A Po (spadek)\n  rnorm(50, 0.61, 0.05), rnorm(50, 0.64, 0.05)  # Woj. B Po (wzrost)\n)\n\ndane &lt;- data.frame(Czas = czas, Wojewodztwo = wojewodztwo, StopaZatrudnienia = stopa_zatrudnienia)\n\n# Tworzenie wykresu\nggplot(dane, aes(x = Czas, y = StopaZatrudnienia, color = Wojewodztwo, group = Wojewodztwo)) +\n  geom_point(position = position_jitter(width = 0.1), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Różnica w Różnicach: Wpływ Podniesienia Płacy Minimalnej na Zatrudnienie\") +\n  xlab(\"Czas\") +\n  ylab(\"Stopa Zatrudnienia\")\n\n\n\n\n\n\n\nFigure 8.4: Analiza DiD: Wpływ podniesienia płacy minimalnej na zatrudnienie",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#podsumowanie",
    "href": "rozdzial4.html#podsumowanie",
    "title": "8  Trafność, Rzetelność i Typy Badań w Naukach Społecznych",
    "section": "8.3 Podsumowanie",
    "text": "8.3 Podsumowanie\nZrozumienie różnych typów badań, wraz z kluczowymi pojęciami trafności i rzetelności, jest niezbędne do projektowania efektywnych badań i interpretacji wyników. Każdy typ badania ma swoje mocne strony i ograniczenia, a wybór odpowiedniej metody zależy od pytania badawczego, dostępnych zasobów i względów etycznych.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#pytania-do-dyskusji",
    "href": "rozdzial4.html#pytania-do-dyskusji",
    "title": "8  Trafność, Rzetelność i Typy Badań w Naukach Społecznych",
    "section": "8.4 Pytania do Dyskusji",
    "text": "8.4 Pytania do Dyskusji\n\nJakie są główne różnice między badaniami eksperymentalnymi, quasi-eksperymentalnymi i obserwacyjnymi?\nW jakich sytuacjach badacz może wybrać projekt quasi-eksperymentalny zamiast prawdziwego eksperymentu?\nJak metoda różnicy w różnicach (DiD) pozwala na wnioskowanie przyczynowe?\nZaprojektuj hipotetyczne badanie wykorzystujące jedną z omówionych metod do zbadania wybranego przez siebie zagadnienia z zakresu nauk społecznych.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#dalsze-czytanie",
    "href": "rozdzial4.html#dalsze-czytanie",
    "title": "8  Trafność, Rzetelność i Typy Badań w Naukach Społecznych",
    "section": "8.5 Dalsze Czytanie",
    "text": "8.5 Dalsze Czytanie\n\nBabbie, E. (2020). “Badania społeczne w praktyce”. Warszawa: Wydawnictwo Naukowe PWN.\nBrzeziński, J. (2019). “Metodologia badań psychologicznych”. Warszawa: Wydawnictwo Naukowe PWN.\nAngrist, J. D., & Pischke, J. S. (2014). “Mastering ’Metrics: The Path from Cause to Effect”. Princeton University Press.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "",
    "text": "9.1 Understanding Outliers\nBefore diving into specific measures, it’s crucial to understand the concept of outliers, as they can significantly impact many descriptive statistics.\nOutliers are data points that differ significantly from other observations in the dataset. They can occur due to:\nOutliers can have a substantial effect on many statistical measures, especially those based on means or sums of squared deviations. Therefore, it’s essential to:\nThroughout this chapter, we’ll discuss how different descriptive measures are affected by outliers.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#understanding-outliers",
    "href": "chapter5.html#understanding-outliers",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "",
    "text": "Measurement or recording errors\nGenuine extreme values in the population\nSampling from a different population\n\n\n\nIdentify outliers through both statistical methods and domain knowledge\nInvestigate the cause of outliers\nMake informed decisions about whether to include or exclude them in analyses",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#arithmetic-mean",
    "href": "chapter5.html#arithmetic-mean",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "10.1 Arithmetic Mean",
    "text": "10.1 Arithmetic Mean\nThe arithmetic mean is the sum of all values divided by the number of values.\nFormula: \\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\\)\nR calculation:\n\ndata &lt;- c(2, 4, 4, 5, 5, 7, 9)\nmean(data)\n\n[1] 5.142857\n\n\nPros:\n\nEasy to calculate and understand\nUses all data points\nUseful for further statistical calculations\n\nCons:\n\nSensitive to outliers\nNot ideal for skewed distributions\n\nExample with outlier:\n\ndata_with_outlier &lt;- c(2, 4, 4, 5, 5, 7, 100)\nmean(data_with_outlier)\n\n[1] 18.14286\n\n\nAs we can see, the outlier (100) drastically affects the mean.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#median",
    "href": "chapter5.html#median",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "10.2 Median",
    "text": "10.2 Median\nThe median is the middle value when the data is ordered.\nR calculation:\n\nmedian(data)\n\n[1] 5\n\nmedian(data_with_outlier)\n\n[1] 5\n\n\nPros:\n\nNot affected by extreme outliers\nBetter for skewed distributions\n\nCons:\n\nDoesn’t use all data points\nLess useful for further statistical calculations",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#mode",
    "href": "chapter5.html#mode",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "10.3 Mode",
    "text": "10.3 Mode\nThe mode is the most frequently occurring value.\nR calculation:\n\nlibrary(modeest)\nmfv(data)  # Most frequent value\n\n[1] 4 5\n\n\nPros:\n\nOnly measure of central tendency for nominal data\nCan identify multiple peaks in the data\n\nCons:\n\nNot always uniquely defined\nNot useful for continuous data",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#weighted-mean",
    "href": "chapter5.html#weighted-mean",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "10.4 Weighted Mean",
    "text": "10.4 Weighted Mean\nThe weighted mean is used when some data points are more important than others. There are two types of weighted means: with not normalized weights and with normalized weights.\n\n10.4.1 Weighted Mean with Not Normalized Weights\nThis is the standard form of the weighted mean, where weights can be any positive numbers representing the importance of each data point.\nFormula: \\(\\bar{x}_w = \\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}\\)\nR calculation:\n\nx &lt;- c(2, 4, 5, 7)\nw &lt;- c(1, 2, 3, 1)\nweighted.mean(x, w)\n\n[1] 4.571429\n\n\n\n\n10.4.2 Weighted Mean with Normalized Weights (Fractions)\nIn this case, the weights are fractions that sum to 1, representing the proportion of importance for each data point.\nFormula: \\(\\bar{x}_w = \\sum_{i=1}^n w_i x_i\\), where \\(\\sum_{i=1}^n w_i = 1\\)\nR calculation:\n\nx &lt;- c(2, 4, 5, 7)\nw_normalized &lt;- c(0.1, 0.3, 0.4, 0.2)  # Note: these sum to 1\nsum(x * w_normalized)\n\n[1] 4.8\n\n\nPros of Weighted Means:\n\nAccount for varying importance of data points\nUseful in survey analysis with different sample sizes or importance levels\nCan adjust for unequal probabilities in sampling designs\n\nCons of Weighted Means:\n\nRequire justification for weights\nCan be misused to manipulate results\nMay be less intuitive to interpret than simple arithmetic mean\n\nComparison:\nThe not normalized weights are often easier to assign based on real-world importance or sample sizes, but require the additional step of normalization in the calculation. Normalized weights (fractions) make the calculation simpler but may be less intuitive to assign directly.\nExample in Social Science:\nSuppose we’re calculating the average income for a region with three cities:\nCity A: Average income $50,000, population 100,000 City B: Average income $60,000, population 200,000 City C: Average income $70,000, population 300,000\nWe can use population as weights:\n\nincomes &lt;- c(50000, 60000, 70000)\npopulations &lt;- c(100000, 200000, 300000)\n\n# Not normalized weights\nweighted.mean(incomes, populations)\n\n[1] 63333.33\n\n# Normalized weights\npop_normalized &lt;- populations / sum(populations)\nsum(incomes * pop_normalized)\n\n[1] 63333.33\n\n\nThis weighted average gives a more accurate representation of the region’s average income than a simple arithmetic mean of the three city averages would.\nPros:\n\nAccounts for varying importance of data points\nUseful in survey analysis with different sample sizes\n\nCons:\n\nRequires justification for weights\nCan be misused to manipulate results",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#range",
    "href": "chapter5.html#range",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "11.1 Range",
    "text": "11.1 Range\nThe range is the difference between the maximum and minimum values.\nFormula: \\(R = x_{max} - x_{min}\\)\nR calculation:\n\nrange(data)\n\n[1] 2 9\n\nmax(data) - min(data)\n\n[1] 7\n\n\nPros:\n\nSimple to calculate and understand\nGives an immediate sense of data spread\n\nCons:\n\nExtremely sensitive to outliers\nDoesn’t provide information about the distribution between extremes",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#interquartile-range-iqr",
    "href": "chapter5.html#interquartile-range-iqr",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "11.2 Interquartile Range (IQR)",
    "text": "11.2 Interquartile Range (IQR)\nThe IQR is the difference between the 75th and 25th percentiles.\nFormula: \\(IQR = Q_3 - Q_1\\)\nR calculation:\n\nIQR(data)\n\n[1] 2\n\n\nPros:\n\nRobust to outliers\nProvides information about the spread of the middle 50% of the data\n\nCons:\n\nIgnores the tails of the distribution\nLess efficient than standard deviation for normal distributions",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#variance",
    "href": "chapter5.html#variance",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "11.3 Variance",
    "text": "11.3 Variance\nVariance measures the average squared deviation from the mean.\nFormula: \\(s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}\\)\nR calculation:\n\nvar(data)\n\n[1] 5.142857\n\n\nPros:\n\nUses all data points\nFoundation for many statistical tests\n\nCons:\n\nUnits are squared, making interpretation less intuitive\nSensitive to outliers",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#standard-deviation",
    "href": "chapter5.html#standard-deviation",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "11.4 Standard Deviation",
    "text": "11.4 Standard Deviation\nThe standard deviation is the square root of the variance.\nFormula: \\(s = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}}\\)\nR calculation:\n\nsd(data)\n\n[1] 2.267787\n\n\nPros:\n\nIn same units as original data\nWidely used and understood\n\nCons:\n\nStill sensitive to outliers\nAssumes data is roughly normally distributed",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#coefficient-of-variation",
    "href": "chapter5.html#coefficient-of-variation",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "11.5 Coefficient of Variation",
    "text": "11.5 Coefficient of Variation\nThe coefficient of variation is the standard deviation divided by the mean, often expressed as a percentage.\nFormula: \\(CV = \\frac{s}{\\bar{x}} \\times 100\\%\\)\nR calculation:\n\n(sd(data) / mean(data)) * 100\n\n[1] 44.09586\n\n\nPros:\n\nAllows comparison of variability between datasets with different units or means\nUseful in fields like finance for risk assessment\n\nCons:\n\nNot meaningful for data with both positive and negative values\nCan be misleading when mean is close to zero",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#percentiles",
    "href": "chapter5.html#percentiles",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "12.1 Percentiles",
    "text": "12.1 Percentiles\nPercentiles divide the data into 100 equal parts.\nFormula: For the kth percentile: \\(P_k = L + \\frac{k(n+1)}{100}\\), where L is the lower limit of the interval\nR calculation:\n\nquantile(data, probs = seq(0, 1, 0.25))\n\n  0%  25%  50%  75% 100% \n   2    4    5    6    9",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#quartiles",
    "href": "chapter5.html#quartiles",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "12.2 Quartiles",
    "text": "12.2 Quartiles\nQuartiles divide the data into four equal parts.\n\nQ1: 25th percentile\nQ2: Median (50th percentile)\nQ3: 75th percentile\n\nR calculation:\n\nsummary(data)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   4.000   5.000   5.143   6.000   9.000 \n\n\nPros:\n\nRobust to outliers\nProvide information about data spread and skewness\n\nCons:\n\nLess precise than using all data points\nMultiple methods of calculation can lead to slightly different results",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#skewness",
    "href": "chapter5.html#skewness",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "13.1 Skewness",
    "text": "13.1 Skewness\nSkewness measures the asymmetry of the probability distribution.\nFormula: \\(SK = \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^n (\\frac{x_i - \\bar{x}}{s})^3\\)\nR calculation:\n\nlibrary(moments)\n\n\nAttaching package: 'moments'\n\n\nThe following object is masked from 'package:modeest':\n\n    skewness\n\nskewness(data)\n\n[1] 0.4592793\n\n\nInterpretation:\n\nPositive skewness: right tail is longer (mean &gt; median)\nNegative skewness: left tail is longer (mean &lt; median)\nZero skewness: symmetrical distribution\n\nPros:\n\nProvides information about distribution shape\nUseful for checking assumptions of normality\n\nCons:\n\nSensitive to outliers\nCan be misleading for multimodal distributions",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#kurtosis",
    "href": "chapter5.html#kurtosis",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "13.2 Kurtosis",
    "text": "13.2 Kurtosis\nKurtosis measures the “tailedness” of the probability distribution.\nFormula: \\(K = \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^n (\\frac{x_i - \\bar{x}}{s})^4 - \\frac{3(n-1)^2}{(n-2)(n-3)}\\)\nR calculation:\n\nkurtosis(data)\n\n[1] 2.457047\n\n\nInterpretation:\n\nPositive kurtosis: heavy tails, peaked distribution\nNegative kurtosis: light tails, flat distribution\nZero kurtosis: normal distribution\n\nPros:\n\nProvides information about extreme values in the distribution\nUseful for financial modeling and risk assessment\n\nCons:\n\nSensitive to outliers\nCan be difficult to interpret practically",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#bivariate-statistics",
    "href": "chapter5.html#bivariate-statistics",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "14.1 Bivariate Statistics",
    "text": "14.1 Bivariate Statistics\n\n14.1.1 Correlation\nCorrelation measures the strength and direction of the linear relationship between two variables.\n\nx &lt;- c(1, 2, 3, 4, 5)\ny &lt;- c(2, 4, 5, 4, 5)\ncor(x, y)\n\n[1] 0.7745967\n\n\n\n\n14.1.2 Covariance\nCovariance measures how two variables vary together.\n\ncov(x, y)\n\n[1] 1.5\n\n\n\n\n14.1.3 Cross-tabulation\nCross-tabulation (contingency table) shows the relationship between two categorical variables.\n\ntable(cut(x, 2), cut(y, 2))\n\n           \n            (2,3.5] (3.5,5]\n  (0.996,3]       1       2\n  (3,5]           0       2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "chapter5.html#multivariate-statistics",
    "href": "chapter5.html#multivariate-statistics",
    "title": "9  Comprehensive Guide to Univariate Descriptive Statistics",
    "section": "14.2 Multivariate Statistics",
    "text": "14.2 Multivariate Statistics\n\nMultiple Correlation: Correlation between a dependent variable and multiple independent variables.\nPartial Correlation: Correlation between two variables while controlling for others.\nFactor Analysis: Technique to reduce many variables to a few underlying factors.\n\nThese topics will be covered in more detail in later chapters.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Validity, Reliability, and Study Types in Social Sciences</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html",
    "href": "rozdzial5.html",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "",
    "text": "10.1 Zrozumienie wartości odstających\nZanim zagłębimy się w konkretne miary, kluczowe jest zrozumienie koncepcji wartości odstających, ponieważ mogą one znacząco wpływać na wiele statystyk opisowych.\nWartości odstające to punkty danych, które znacznie różnią się od innych obserwacji w zbiorze danych. Mogą wystąpić z powodu:\nWartości odstające mogą mieć istotny wpływ na wiele miar statystycznych, szczególnie tych opartych na średnich lub sumach kwadratów odchyleń. Dlatego ważne jest, aby:\nW trakcie tego rozdziału omówimy, jak różne miary opisowe są dotknięte przez wartości odstające.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#zrozumienie-wartości-odstających",
    "href": "rozdzial5.html#zrozumienie-wartości-odstających",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "",
    "text": "Błędów pomiaru lub rejestracji\nPrawdziwych skrajnych wartości w populacji\nPróbkowania z innej populacji\n\n\n\nIdentyfikować wartości odstające zarówno poprzez metody statystyczne, jak i wiedzę dziedzinową\nBadać przyczyny występowania wartości odstających\nPodejmować świadome decyzje o tym, czy włączyć je do analiz, czy nie",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#średnia-arytmetyczna",
    "href": "rozdzial5.html#średnia-arytmetyczna",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "11.1 Średnia arytmetyczna",
    "text": "11.1 Średnia arytmetyczna\nŚrednia arytmetyczna to suma wszystkich wartości podzielona przez liczbę wartości.\nWzór: \\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\\)\nObliczenie w R:\n\ndane &lt;- c(2, 4, 4, 5, 5, 7, 9)\nmean(dane)\n\n[1] 5.142857\n\n\nZalety:\n\nŁatwa do obliczenia i zrozumienia\nWykorzystuje wszystkie punkty danych\nPrzydatna do dalszych obliczeń statystycznych\n\nWady:\n\nWrażliwa na wartości odstające\nNieidealna dla rozkładów skośnych\n\nPrzykład z wartością odstającą:\n\ndane_z_odstajaca &lt;- c(2, 4, 4, 5, 5, 7, 100)\nmean(dane_z_odstajaca)\n\n[1] 18.14286\n\n\nJak widać, wartość odstająca (100) drastycznie wpływa na średnią.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#mediana",
    "href": "rozdzial5.html#mediana",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "11.2 Mediana",
    "text": "11.2 Mediana\nMediana to środkowa wartość, gdy dane są uporządkowane.\nObliczenie w R:\n\nmedian(dane)\n\n[1] 5\n\nmedian(dane_z_odstajaca)\n\n[1] 5\n\n\nZalety:\n\nNie jest dotknięta przez skrajne wartości odstające\nLepsza dla rozkładów skośnych\n\nWady:\n\nNie wykorzystuje wszystkich punktów danych\nMniej przydatna do dalszych obliczeń statystycznych",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#moda",
    "href": "rozdzial5.html#moda",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "11.3 Moda",
    "text": "11.3 Moda\nModa to najczęściej występująca wartość.\nObliczenie w R:\n\nlibrary(modeest)\nmfv(dane)  # Najczęściej występująca wartość\n\n[1] 4 5\n\n\nZalety:\n\nJedyna miara tendencji centralnej dla danych nominalnych\nMoże identyfikować wiele szczytów w danych\n\nWady:\n\nNie zawsze jednoznacznie zdefiniowana\nNieprzydatna dla danych ciągłych",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#średnia-ważona",
    "href": "rozdzial5.html#średnia-ważona",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "11.4 Średnia ważona",
    "text": "11.4 Średnia ważona\nŚrednia ważona jest używana, gdy niektóre punkty danych są ważniejsze od innych. Rozróżniamy dwa typy średnich ważonych: z wagami nienormalizowanymi i z wagami znormalizowanymi.\n\n11.4.1 Średnia ważona z wagami nienormalizowanymi\nJest to standardowa forma średniej ważonej, gdzie wagi mogą być dowolnymi liczbami dodatnimi reprezentującymi ważność każdego punktu danych.\nWzór: \\(\\bar{x}_w = \\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}\\)\nObliczenie w R:\n\nx &lt;- c(2, 4, 5, 7)\nw &lt;- c(1, 2, 3, 1)\nweighted.mean(x, w)\n\n[1] 4.571429\n\n\n\n\n11.4.2 Średnia ważona z wagami znormalizowanymi (ułamkami)\nW tym przypadku wagi są ułamkami sumującymi się do 1, reprezentującymi proporcję ważności dla każdego punktu danych.\nWzór: \\(\\bar{x}_w = \\sum_{i=1}^n w_i x_i\\), gdzie \\(\\sum_{i=1}^n w_i = 1\\)\nObliczenie w R:\n\nx &lt;- c(2, 4, 5, 7)\nw_znormalizowane &lt;- c(0.1, 0.3, 0.4, 0.2)  # Uwaga: te sumują się do 1\nsum(x * w_znormalizowane)\n\n[1] 4.8\n\n\nZalety średnich ważonych:\n\nUwzględniają różną ważność punktów danych\nPrzydatne w analizie badań z różnymi wielkościami próby lub poziomami ważności\nMogą korygować nierówne prawdopodobieństwa w projektach próbkowania\n\nWady średnich ważonych:\n\nWymagają uzasadnienia dla wag\nMogą być niewłaściwie użyte do manipulacji wynikami\nMogą być mniej intuicyjne w interpretacji niż prosta średnia arytmetyczna\n\nPorównanie:\nWagi nienormalizowane są często łatwiejsze do przypisania na podstawie rzeczywistej ważności lub wielkości próby, ale wymagają dodatkowego kroku normalizacji w obliczeniach. Wagi znormalizowane (ułamki) upraszczają obliczenia, ale mogą być mniej intuicyjne do bezpośredniego przypisania.\nPrzykład w naukach społecznych:\nZałóżmy, że obliczamy średni dochód dla regionu z trzema miastami:\nMiasto A: Średni dochód 50 000 zł, populacja 100 000 Miasto B: Średni dochód 60 000 zł, populacja 200 000 Miasto C: Średni dochód 70 000 zł, populacja 300 000\nMożemy użyć populacji jako wag:\n\ndochody &lt;- c(50000, 60000, 70000)\npopulacje &lt;- c(100000, 200000, 300000)\n\n# Wagi nienormalizowane\nweighted.mean(dochody, populacje)\n\n[1] 63333.33\n\n# Wagi znormalizowane\npop_znormalizowane &lt;- populacje / sum(populacje)\nsum(dochody * pop_znormalizowane)\n\n[1] 63333.33\n\n\nTa średnia ważona daje dokładniejsze przedstawienie średniego dochodu regionu niż prosta średnia arytmetyczna średnich dochodów trzech miast.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#rozstęp",
    "href": "rozdzial5.html#rozstęp",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "12.1 Rozstęp",
    "text": "12.1 Rozstęp\nRozstęp to różnica między wartością maksymalną a minimalną.\nWzór: \\(R = x_{max} - x_{min}\\)\nObliczenie w R:\n\nrange(dane)\n\n[1] 2 9\n\nmax(dane) - min(dane)\n\n[1] 7\n\n\nZalety:\n\nProsty do obliczenia i zrozumienia\nDaje natychmiastowe poczucie rozpiętości danych\n\nWady:\n\nNiezwykle wrażliwy na wartości odstające\nNie dostarcza informacji o rozkładzie między skrajnościami",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#rozstęp-międzykwartylowy-iqr",
    "href": "rozdzial5.html#rozstęp-międzykwartylowy-iqr",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "12.2 Rozstęp międzykwartylowy (IQR)",
    "text": "12.2 Rozstęp międzykwartylowy (IQR)\nIQR to różnica między 75. a 25. percentylem.\nWzór: \\(IQR = Q_3 - Q_1\\)\nObliczenie w R:\n\nIQR(dane)\n\n[1] 2\n\n\nZalety:\n\nOdporny na wartości odstające\nDostarcza informacji o rozpiętości środkowych 50% danych\n\nWady:\n\nIgnoruje ogony rozkładu\nMniej efektywny niż odchylenie standardowe dla rozkładów normalnych",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#wariancja",
    "href": "rozdzial5.html#wariancja",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "12.3 Wariancja",
    "text": "12.3 Wariancja\nWariancja mierzy średnie kwadratowe odchylenie od średniej.\nWzór: \\(s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}\\)\nObliczenie w R:\n\nvar(dane)\n\n[1] 5.142857\n\n\nZalety:\n\nWykorzystuje wszystkie punkty danych\nPodstawa dla wielu testów statystycznych\n\nWady:\n\nJednostki są podniesione do kwadratu, co utrudnia interpretację\nWrażliwa na wartości odstające",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#odchylenie-standardowe",
    "href": "rozdzial5.html#odchylenie-standardowe",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "12.4 Odchylenie standardowe",
    "text": "12.4 Odchylenie standardowe\nOdchylenie standardowe to pierwiastek kwadratowy z wariancji.\nWzór: \\(s = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}}\\)\nObliczenie w R:\n\nsd(dane)\n\n[1] 2.267787\n\n\nZalety:\n\nW tych samych jednostkach co oryginalne dane\nSzeroko stosowane i rozumiane\n\nWady:\n\nNadal wrażliwe na wartości odstające\nZakłada, że dane są w przybliżeniu normalnie rozłożone",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#współczynnik-zmienności",
    "href": "rozdzial5.html#współczynnik-zmienności",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "12.5 Współczynnik zmienności",
    "text": "12.5 Współczynnik zmienności\nWspółczynnik zmienności to odchylenie standardowe podzielone przez średnią, często wyrażane jako procent.\nWzór: \\(CV = \\frac{s}{\\bar{x}} \\times 100\\%\\)\nObliczenie w R:\n\n(sd(dane) / mean(dane)) * 100\n\n[1] 44.09586\n\n\nZalety:\n\nPozwala na porównanie zmienności między zbiorami danych o różnych jednostkach lub średnich\nPrzydatny w dziedzinach takich jak finanse do oceny ryzyka\n\nWady:\n\nNie ma sensu dla danych z wartościami zarówno dodatnimi, jak i ujemnymi\nMoże być mylący, gdy średnia jest bliska zeru",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#percentyle",
    "href": "rozdzial5.html#percentyle",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "13.1 Percentyle",
    "text": "13.1 Percentyle\nPercentyle dzielą dane na 100 równych części.\nWzór: Dla k-tego percentyla: \\(P_k = L + \\frac{k(n+1)}{100}\\), gdzie L to dolna granica przedziału\nObliczenie w R:\n\nquantile(dane, probs = seq(0, 1, 0.25))\n\n  0%  25%  50%  75% 100% \n   2    4    5    6    9",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#kwartyle",
    "href": "rozdzial5.html#kwartyle",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "13.2 Kwartyle",
    "text": "13.2 Kwartyle\nKwartyle dzielą dane na cztery równe części.\n\nQ1: 25. percentyl\nQ2: Mediana (50. percentyl)\nQ3: 75. percentyl\n\nObliczenie w R:\n\nsummary(dane)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   4.000   5.000   5.143   6.000   9.000 \n\n\nZalety:\n\nOdporne na wartości odstające\nDostarczają informacji o rozpiętości i skośności danych\n\nWady:\n\nMniej precyzyjne niż użycie wszystkich punktów danych\nRóżne metody obliczania mogą prowadzić do nieznacznie różnych wyników",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#skośność",
    "href": "rozdzial5.html#skośność",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "14.1 Skośność",
    "text": "14.1 Skośność\nSkośność mierzy asymetrię rozkładu prawdopodobieństwa.\nWzór: \\(SK = \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^n (\\frac{x_i - \\bar{x}}{s})^3\\)\nObliczenie w R:\n\nlibrary(moments)\n\n\nAttaching package: 'moments'\n\n\nThe following object is masked from 'package:modeest':\n\n    skewness\n\nskewness(dane)\n\n[1] 0.4592793\n\n\nInterpretacja:\n\nSkośność dodatnia: prawy ogon jest dłuższy (średnia &gt; mediana)\nSkośność ujemna: lewy ogon jest dłuższy (średnia &lt; mediana)\nSkośność zero: rozkład symetryczny\n\nZalety:\n\nDostarcza informacji o kształcie rozkładu\nPrzydatna do sprawdzania założeń normalności\n\nWady:\n\nWrażliwa na wartości odstające\nMoże być myląca dla rozkładów wielomodalnych",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#kurtoza",
    "href": "rozdzial5.html#kurtoza",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "14.2 Kurtoza",
    "text": "14.2 Kurtoza\nKurtoza mierzy “grubość ogonów” rozkładu prawdopodobieństwa.\nWzór: \\(K = \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^n (\\frac{x_i - \\bar{x}}{s})^4 - \\frac{3(n-1)^2}{(n-2)(n-3)}\\)\nObliczenie w R:\n\nkurtosis(dane)\n\n[1] 2.457047\n\n\nInterpretacja:\n\nKurtoza dodatnia: ciężkie ogony, rozkład wysmukły\nKurtoza ujemna: lekkie ogony, rozkład płaski\nKurtoza zero: rozkład normalny\n\nZalety:\n\nDostarcza informacji o wartościach skrajnych w rozkładzie\nPrzydatna do modelowania finansowego i oceny ryzyka\n\nWady:\n\nWrażliwa na wartości odstające\nMoże być trudna do praktycznej interpretacji",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#statystyki-dwuwymiarowe",
    "href": "rozdzial5.html#statystyki-dwuwymiarowe",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "15.1 Statystyki dwuwymiarowe",
    "text": "15.1 Statystyki dwuwymiarowe\n\n15.1.1 Korelacja\nKorelacja mierzy siłę i kierunek liniowego związku między dwiema zmiennymi.\n\nx &lt;- c(1, 2, 3, 4, 5)\ny &lt;- c(2, 4, 5, 4, 5)\ncor(x, y)\n\n[1] 0.7745967\n\n\n\n\n15.1.2 Kowariancja\nKowariancja mierzy, jak dwie zmienne zmieniają się razem.\n\ncov(x, y)\n\n[1] 1.5\n\n\n\n\n15.1.3 Tabela krzyżowa\nTabela krzyżowa (tabela kontyngencji) pokazuje relację między dwiema zmiennymi kategorialnymi.\n\ntable(cut(x, 2), cut(y, 2))\n\n           \n            (2,3.5] (3.5,5]\n  (0.996,3]       1       2\n  (3,5]           0       2",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "rozdzial5.html#statystyki-wielowymiarowe",
    "href": "rozdzial5.html#statystyki-wielowymiarowe",
    "title": "10  Kompleksowy przewodnik po jednowymiarowych statystykach opisowych",
    "section": "15.2 Statystyki wielowymiarowe",
    "text": "15.2 Statystyki wielowymiarowe\n\nKorelacja wielokrotna: Korelacja między zmienną zależną a wieloma zmiennymi niezależnymi.\nKorelacja cząstkowa: Korelacja między dwiema zmiennymi przy kontrolowaniu innych.\nAnaliza czynnikowa: Technika redukcji wielu zmiennych do kilku podstawowych czynników.\n\nTe tematy zostaną omówione bardziej szczegółowo w kolejnych rozdziałach.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Trafność, Rzetelność i Typy Badań w Naukach Społecznych</span>"
    ]
  },
  {
    "objectID": "chapter4.html#introduction",
    "href": "chapter4.html#introduction",
    "title": "7  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "",
    "text": "Experimental designs\nNon-experimental designs: Observational/Descriptive\nQuasi-experimental designs",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#the-neyman-rubin-potential-outcome-framework",
    "href": "chapter4.html#the-neyman-rubin-potential-outcome-framework",
    "title": "9  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "9.5 The Neyman-Rubin Potential Outcome Framework",
    "text": "9.5 The Neyman-Rubin Potential Outcome Framework\nThe Neyman-Rubin potential outcome framework provides a formal approach to causal inference. It introduces the concept of potential outcomes: for each unit, we consider the outcome under treatment and the outcome under control, even though we can only observe one in reality.\nKey concepts:\n\nPotential Outcomes: \\(Y_i(1)\\) and \\(Y_i(0)\\) for treatment and control, respectively.\nObserved Outcome: \\(Y_i = Y_i(1)T_i + Y_i(0)(1-T_i)\\), where \\(T_i\\) is the treatment indicator.\nIndividual Treatment Effect: \\(\\tau_i = Y_i(1) - Y_i(0)\\)\nAverage Treatment Effect (ATE): \\(E[\\tau_i] = E[Y_i(1) - Y_i(0)]\\)\n\nThe framework emphasizes the “fundamental problem of causal inference”: we can never observe both potential outcomes for a single unit simultaneously.\n\n9.5.1 Example: Estimating ATE in an RCT\nIn an RCT, random assignment ensures that treatment is independent of potential outcomes, allowing unbiased estimation of the ATE:\n\\[\n\\hat{ATE} = \\frac{1}{n_1} \\sum_{i:T_i=1} Y_i - \\frac{1}{n_0} \\sum_{i:T_i=0} Y_i\n\\]\nWhere \\(n_1\\) and \\(n_0\\) are the numbers of treated and control units, respectively.\n\n# Using the RCT data from earlier\nate_estimate &lt;- mean(data$post_test[data$group == \"Treatment\"]) - \n                mean(data$post_test[data$group == \"Control\"])\n\nWarning in mean.default(data$post_test[data$group == \"Treatment\"]): argument is\nnot numeric or logical: returning NA\n\n\nWarning in mean.default(data$post_test[data$group == \"Control\"]): argument is\nnot numeric or logical: returning NA\n\ncat(\"Estimated Average Treatment Effect:\", round(ate_estimate, 2))\n\nEstimated Average Treatment Effect: NA\n\n\nThis estimate represents the causal effect of the treatment under the assumptions of the potential outcome framework.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#experimental-designs",
    "href": "chapter4.html#experimental-designs",
    "title": "9  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "9.2 Experimental Designs",
    "text": "9.2 Experimental Designs\nExperimental designs are characterized by the researcher’s control over the independent variable(s) and random assignment of subjects to different conditions. These designs are considered the gold standard for establishing causal relationships.\n\n9.2.1 Randomized Controlled Trials (RCTs)\nRCTs are the most rigorous form of experimental design. They involve:\n\nRandom assignment of subjects to treatment and control groups\nManipulation of the independent variable\nMeasurement of the dependent variable\n\nLet’s visualize a simple RCT design:\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nset.seed(123)\n\n# Create sample data\nn &lt;- 100\ndata &lt;- data.frame(\n  id = 1:n,\n  group = factor(rep(c(\"Control\", \"Treatment\"), each = n/2)),\n  pre_test = rnorm(n, mean = 50, sd = 10),\n  post_test = NA\n)\n\n# Simulate treatment effect\ndata$post_test &lt;- ifelse(data$group == \"Treatment\",\n                         data$pre_test + rnorm(n/2, mean = 10, sd = 5),\n                         data$pre_test + rnorm(n/2, mean = 0, sd = 5))\n\n# Reshape data for plotting\ndata_long &lt;- tidyr::pivot_longer(data, cols = c(pre_test, post_test),\n                                 names_to = \"time\", values_to = \"score\")\n\n# Create plot\nggplot(data_long, aes(x = time, y = score, color = group, group = interaction(id, group))) +\n  geom_line(alpha = 0.3) +\n  geom_point(alpha = 0.5) +\n  stat_summary(aes(group = group), fun = mean, geom = \"line\", size = 1.5) +\n  labs(title = \"Pre-test and Post-test Scores in RCT\",\n       x = \"Time\", y = \"Score\", color = \"Group\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nRandomized Controlled Trial Design\n\n\n\n\nThis plot shows individual trajectories and group means for pre-test and post-test scores in a hypothetical RCT. The treatment group shows a clear increase in scores compared to the control group.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#non-experimental-designs-observationaldescriptive",
    "href": "chapter4.html#non-experimental-designs-observationaldescriptive",
    "title": "7  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "7.4 2. Non-Experimental Designs: Observational/Descriptive",
    "text": "7.4 2. Non-Experimental Designs: Observational/Descriptive\nObservational studies involve collecting and analyzing data without manipulating the environment. While these designs can’t establish causality as reliably as experiments, they’re often necessary when experiments are impractical or unethical.\n\n7.4.1 Key Features of Observational Designs:\n\nNo manipulation of independent variables\nPotential for confounding factors\nOften used for generating hypotheses or describing relationships\n\n\n\n7.4.2 Example: Observational Study using R\nLet’s simulate an observational study looking at the relationship between education and income:\n\nset.seed(456)\nn &lt;- 1000\n\n# Generate data\ndata &lt;- data.frame(\n  id = 1:n,\n  education = rnorm(n, mean = 12, sd = 2),  # years of education\n  ability = rnorm(n),  # unobserved ability\n  income = rnorm(n, mean = 30000, sd = 10000)  # annual income\n)\n\n# True relationship: income depends on both education and unobserved ability\ndata$income &lt;- data$income + 2000 * data$education + 5000 * data$ability\n\n# Naive regression (ignoring ability)\nmodel_naive &lt;- lm(income ~ education, data = data)\nsummary(model_naive)\n\n\nCall:\nlm(formula = income ~ education, data = data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-42409  -7142    -97   7586  39600 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28783.8     2178.8   13.21   &lt;2e-16 ***\neducation     2094.2      177.6   11.79   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11010 on 998 degrees of freedom\nMultiple R-squared:  0.1223,    Adjusted R-squared:  0.1214 \nF-statistic: 139.1 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n# Plot\nplot(data$education, data$income, main = \"Education vs Income\", \n     xlab = \"Years of Education\", ylab = \"Annual Income\")\nabline(model_naive, col = \"red\")\n\n\n\n\n\n\n\n\nIn this example, we see a positive relationship between education and income. However, because we can’t control for unobserved ability, we can’t claim this relationship is causal.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#quasi-experimental-designs",
    "href": "chapter4.html#quasi-experimental-designs",
    "title": "7  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "7.5 3. Quasi-Experimental Designs",
    "text": "7.5 3. Quasi-Experimental Designs\nQuasi-experimental designs attempt to approximate experimental designs when randomization is not possible. We’ll focus on two popular quasi-experimental methods: Difference-in-Differences (DiD) and Regression Discontinuity Design (RDD).\n\n7.5.1 Difference-in-Differences (DiD)\nDiD is used when we have data on treatment and control groups before and after an intervention.\n\n7.5.1.1 Example: DiD using the plm package\nLet’s simulate a DiD scenario and analyze it using the plm package:\n\nlibrary(plm)\n\nset.seed(789)\nn &lt;- 1000\nt &lt;- 4  # time periods\n\n# Generate panel data\ndata &lt;- data.frame(\n  id = rep(1:n, each = t),\n  time = rep(1:t, n),\n  treatment = rep(rbinom(n, 1, 0.5), each = t),\n  Y = rnorm(n * t)\n)\n\n# Add treatment effect\ndata$Y[data$treatment == 1 & data$time &gt;= 3] &lt;- \n  data$Y[data$treatment == 1 & data$time &gt;= 3] + 0.5\n\n# Convert to panel data\npdata &lt;- pdata.frame(data, index = c(\"id\", \"time\"))\n\n# DiD model\ndid_model &lt;- plm(Y ~ treatment:factor(time), data = pdata, model = \"within\")\nsummary(did_model)\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = Y ~ treatment:factor(time), data = pdata, model = \"within\")\n\nBalanced Panel: n = 1000, T = 4, N = 4000\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-3.476976 -0.576560 -0.016051  0.568876  3.098016 \n\nCoefficients: (1 dropped because of singularities)\n                          Estimate Std. Error t-value  Pr(&gt;|t|)    \ntreatment:factor(time)1 -0.4542117  0.0630027 -7.2094 7.083e-13 ***\ntreatment:factor(time)2 -0.5343396  0.0630027 -8.4812 &lt; 2.2e-16 ***\ntreatment:factor(time)3  0.0019631  0.0630027  0.0312    0.9751    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    3104.5\nResidual Sum of Squares: 2980\nR-Squared:      0.040102\nAdj. R-Squared: -0.28083\nF-statistic: 41.7352 on 3 and 2997 DF, p-value: &lt; 2.22e-16\n\n\nThis example demonstrates how to implement and interpret a DiD model using the plm package.\n\n\n\n7.5.2 Regression Discontinuity Design (RDD)\nRDD is used when treatment assignment is determined by a cutoff value of a running variable.\n\n7.5.2.1 Example: RDD using the rdrobust package\nLet’s simulate an RDD scenario and analyze it using the rdrobust package:\n\nlibrary(rdrobust)\n\nset.seed(101)\nn &lt;- 1000\n\n# Generate data\ndata &lt;- data.frame(\n  X = runif(n, -1, 1),  # running variable\n  Y = rnorm(n)\n)\n\n# Add treatment effect\ncutoff &lt;- 0\ndata$D &lt;- ifelse(data$X &gt;= cutoff, 1, 0)\ndata$Y &lt;- data$Y + 0.5 * data$D + 0.3 * data$X\n\n# RDD analysis\nrdd_result &lt;- rdrobust(y = data$Y, x = data$X, c = cutoff)\nsummary(rdd_result)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1000\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  521          479\nEff. Number of Obs.             156          128\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   0.297        0.297\nBW bias (b)                   0.472        0.472\nrho (h/b)                     0.630        0.630\nUnique Obs.                     521          479\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.558     0.283     1.976     0.048     [0.004 , 1.112]     \n        Robust         -         -     1.553     0.120    [-0.139 , 1.196]     \n=============================================================================\n\n# Plot\nrdplot(y = data$Y, x = data$X, c = cutoff)\n\n\n\n\n\n\n\n\nThis example demonstrates how to implement and interpret an RDD model using the rdrobust package.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#references",
    "href": "chapter4.html#references",
    "title": "9  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "9.7 References",
    "text": "9.7 References\n\nImbens, G. W., & Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press.\nAngrist, J. D., & Pischke, J. S. (2008). Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press.\nShadish, W. R., Cook, T. D., & Campbell, D. T. (2002). Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Houghton Mifflin.\nCunningham, S. (2021). Causal Inference: The Mixtape. Yale University Press.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter4.html#non-experimental-designs",
    "href": "chapter4.html#non-experimental-designs",
    "title": "9  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "9.4 Non-Experimental Designs",
    "text": "9.4 Non-Experimental Designs\nNon-experimental designs are used when randomization or manipulation of variables is not possible or ethical. They include observational/descriptive studies and quasi-experimental designs.\n\n9.4.1 Observational Studies\nObservational studies involve collecting data without manipulating variables. They are useful for exploring relationships and generating hypotheses.\nExample: Correlation study\n\nset.seed(789)\nn &lt;- 100\nstudy_time &lt;- runif(n, 0, 10)\nexam_score &lt;- 50 + 5 * study_time + rnorm(n, 0, 10)\n\ncorrelation_data &lt;- data.frame(study_time, exam_score)\n\nggplot(correlation_data, aes(x = study_time, y = exam_score)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Correlation between Study Time and Exam Score\",\n       x = \"Study Time (hours)\", y = \"Exam Score\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCorrelation between Study Time and Exam Score\n\n\n\n\nThis scatter plot shows the relationship between study time and exam scores, illustrating a positive correlation typical in observational studies.\n\n\n9.4.2 Quasi-Experimental Designs\nQuasi-experimental designs lack random assignment but attempt to establish causal relationships. Common types include:\n\nDifference-in-Differences (DiD)\nRegression Discontinuity Design (RDD)\n\n\n9.4.2.1 Difference-in-Differences (DiD)\nDiD is used to estimate treatment effects by comparing the average change over time in the outcome variable for the treatment group to the average change over time for the control group.\nLet’s simulate a DiD analysis using the plm package:\n\nlibrary(plm)\n\n\nAttaching package: 'plm'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, lag, lead\n\n# Generate synthetic panel data\nset.seed(101)\nn &lt;- 1000\ntime_periods &lt;- 5\n\npanel_data &lt;- data.frame(\n  id = rep(1:n, each = time_periods),\n  time = rep(1:time_periods, times = n),\n  treatment = rep(sample(c(0, 1), n, replace = TRUE), each = time_periods),\n  outcome = NA\n)\n\n# Generate outcomes\npanel_data$outcome &lt;- with(panel_data,\n                           10 + 2 * time + 5 * treatment + 3 * (time &gt;= 3 & treatment == 1) + rnorm(n * time_periods, 0, 2))\n\n# Estimate DiD model\ndid_model &lt;- plm(outcome ~ treatment * factor(time), \n                 data = panel_data, \n                 index = c(\"id\", \"time\"), \n                 model = \"within\")\n\n# Summarize results\nsummary(did_model)\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = outcome ~ treatment * factor(time), data = panel_data, \n    model = \"within\", index = c(\"id\", \"time\"))\n\nBalanced Panel: n = 1000, T = 5, N = 5000\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-5.932194 -1.200686 -0.033411  1.236533  6.439693 \n\nCoefficients:\n                         Estimate Std. Error t-value Pr(&gt;|t|)    \nfactor(time)2            2.077222   0.124505 16.6838   &lt;2e-16 ***\nfactor(time)3            4.161871   0.124505 33.4273   &lt;2e-16 ***\nfactor(time)4            5.960653   0.124505 47.8748   &lt;2e-16 ***\nfactor(time)5            8.164066   0.124505 65.5722   &lt;2e-16 ***\ntreatment:factor(time)2 -0.020059   0.180272 -0.1113   0.9114    \ntreatment:factor(time)3  2.688227   0.180272 14.9121   &lt;2e-16 ***\ntreatment:factor(time)4  3.084521   0.180272 17.1104   &lt;2e-16 ***\ntreatment:factor(time)5  2.867242   0.180272 15.9051   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    78894\nResidual Sum of Squares: 16182\nR-Squared:      0.79489\nAdj. R-Squared: 0.74315\nF-statistic: 1933.82 on 8 and 3992 DF, p-value: &lt; 2.22e-16\n\n# Visualize DiD\nggplot(panel_data, aes(x = time, y = outcome, color = factor(treatment), group = treatment)) +\n  stat_summary(fun = mean, geom = \"line\", size = 1) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  geom_vline(xintercept = 3, linetype = \"dashed\", color = \"gray50\") +\n  labs(title = \"Difference-in-Differences Analysis\",\n       x = \"Time\", y = \"Outcome\", color = \"Treatment\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\nDifference-in-Differences Analysis\n\n\n\n\nThe plot shows the average outcomes for treatment and control groups over time. The vertical dashed line indicates the intervention point. The DiD estimate is the difference between the two groups’ changes from pre- to post-intervention periods.\n\n\n9.4.2.2 Regression Discontinuity Design (RDD)\nRDD is used when treatment assignment is determined by a cutoff value on a continuous variable. It compares observations just above and below the cutoff to estimate the treatment effect.\nLet’s implement an RDD analysis using the rdrobust package:\n\nlibrary(rdrobust)\n\n# Generate synthetic RDD data\nset.seed(202)\nn &lt;- 1000\nx &lt;- runif(n, -1, 1)\ny &lt;- 3 + 2 * x + 4 * (x &gt;= 0) + rnorm(n, 0, 1)\n\nrdd_data &lt;- data.frame(x, y)\n\n# RDD analysis\nrdd_result &lt;- rdrobust(y, x, c = 0)\nsummary(rdd_result)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1000\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  499          501\nEff. Number of Obs.             182          175\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   0.362        0.362\nBW bias (b)                   0.575        0.575\nrho (h/b)                     0.630        0.630\nUnique Obs.                     499          501\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     4.092     0.231    17.723     0.000     [3.640 , 4.545]     \n        Robust         -         -    15.013     0.000     [3.600 , 4.680]     \n=============================================================================\n\n# Visualize RDD\nggplot(rdd_data, aes(x = x, y = y)) +\n  geom_point(alpha = 0.4) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(data = subset(rdd_data, x &lt; 0), method = \"lm\", se = FALSE, color = \"blue\") +\n  geom_smooth(data = subset(rdd_data, x &gt;= 0), method = \"lm\", se = FALSE, color = \"green\") +\n  labs(title = \"Regression Discontinuity Design\",\n       x = \"Running Variable\", y = \"Outcome\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nRegression Discontinuity Design Analysis\n\n\n\n\nThe plot shows the discontinuity at the cutoff point (x = 0), with separate regression lines fitted on either side. The treatment effect is estimated by the gap between these lines at the cutoff.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#projekty-eksperymentalne",
    "href": "rozdzial4.html#projekty-eksperymentalne",
    "title": "8  Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne",
    "section": "8.2 Projekty Eksperymentalne",
    "text": "8.2 Projekty Eksperymentalne\nProjekty eksperymentalne charakteryzują się kontrolą badacza nad zmienną(ymi) niezależną(ymi) oraz losowym przydziałem uczestników do różnych warunków. Te projekty są uważane za złoty standard w ustalaniu związków przyczynowych.\n\n8.2.1 Randomizowane Badania Kontrolowane (RCT)\nRCT są najbardziej rygorystyczną formą projektu eksperymentalnego. Obejmują one:\n\nLosowy przydział uczestników do grup eksperymentalnej i kontrolnej\nManipulację zmienną niezależną\nPomiar zmiennej zależnej\n\nZobaczmy wizualizację prostego projektu RCT:\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nset.seed(123)\n\n# Tworzenie przykładowych danych\nn &lt;- 100\ndata &lt;- data.frame(\n  id = 1:n,\n  grupa = factor(rep(c(\"Kontrolna\", \"Eksperymentalna\"), each = n/2)),\n  pre_test = rnorm(n, mean = 50, sd = 10),\n  post_test = NA\n)\n\n# Symulacja efektu leczenia\ndata$post_test &lt;- ifelse(data$grupa == \"Eksperymentalna\",\n                         data$pre_test + rnorm(n/2, mean = 10, sd = 5),\n                         data$pre_test + rnorm(n/2, mean = 0, sd = 5))\n\n# Przekształcenie danych do formatu długiego\ndata_long &lt;- tidyr::pivot_longer(data, cols = c(pre_test, post_test),\n                                 names_to = \"czas\", values_to = \"wynik\")\n\n# Tworzenie wykresu\nggplot(data_long, aes(x = czas, y = wynik, color = grupa, group = interaction(id, grupa))) +\n  geom_line(alpha = 0.3) +\n  geom_point(alpha = 0.5) +\n  stat_summary(aes(group = grupa), fun = mean, geom = \"line\", size = 1.5) +\n  labs(title = \"Wyniki Pre-test i Post-test w RCT\",\n       x = \"Czas\", y = \"Wynik\", color = \"Grupa\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\") +\n  scale_x_discrete(labels = c(\"pre_test\" = \"Pre-test\", \"post_test\" = \"Post-test\"))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nProjekt Randomizowanego Badania Kontrolowanego\n\n\n\n\nTen wykres pokazuje indywidualne trajektorie i średnie grupowe dla wyników pre-test i post-test w hipotetycznym RCT. Grupa eksperymentalna wykazuje wyraźny wzrost wyników w porównaniu do grupy kontrolnej.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#projekty-nieeksperymentalne",
    "href": "rozdzial4.html#projekty-nieeksperymentalne",
    "title": "8  Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne",
    "section": "8.4 Projekty Nieeksperymentalne",
    "text": "8.4 Projekty Nieeksperymentalne\nProjekty nieeksperymentalne są stosowane, gdy randomizacja lub manipulacja zmiennymi nie jest możliwa lub etyczna. Obejmują one badania obserwacyjne/opisowe i quasi-eksperymentalne.\n\n8.4.1 Badania Obserwacyjne\nBadania obserwacyjne polegają na zbieraniu danych bez manipulowania zmiennymi. Są one przydatne do eksploracji relacji i generowania hipotez.\nPrzykład: Badanie korelacyjne\n\nset.seed(789)\nn &lt;- 100\nczas_nauki &lt;- runif(n, 0, 10)\nwynik_egzaminu &lt;- 50 + 5 * czas_nauki + rnorm(n, 0, 10)\n\ncorrelation_data &lt;- data.frame(czas_nauki, wynik_egzaminu)\n\nggplot(correlation_data, aes(x = czas_nauki, y = wynik_egzaminu)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Korelacja między Czasem Nauki a Wynikiem Egzaminu\",\n       x = \"Czas Nauki (godziny)\", y = \"Wynik Egzaminu\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nKorelacja między Czasem Nauki a Wynikiem Egzaminu\n\n\n\n\nTen wykres punktowy pokazuje relację między czasem nauki a wynikami egzaminu, ilustrując pozytywną korelację typową dla badań obserwacyjnych.\n\n\n8.4.2 Projekty Quasi-Eksperymentalne\nProjekty quasi-eksperymentalne nie mają losowego przydziału, ale próbują ustalić związki przyczynowe. Popularne typy to:\n\nRóżnica w Różnicach (DiD)\nRegresja Nieciągła (RDD)\n\n\n8.4.2.1 Różnica w Różnicach (DiD)\nDiD jest używana do oszacowania efektów interwencji poprzez porównanie średniej zmiany w czasie w zmiennej wynikowej dla grupy eksperymentalnej ze średnią zmianą w czasie dla grupy kontrolnej.\nPrzeprowadźmy symulację analizy DiD przy użyciu pakietu plm:\n\nlibrary(plm)\n\n\nAttaching package: 'plm'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, lag, lead\n\n# Generowanie syntetycznych danych panelowych\nset.seed(101)\nn &lt;- 1000\nokresy_czasu &lt;- 5\n\npanel_data &lt;- data.frame(\n  id = rep(1:n, each = okresy_czasu),\n  czas = rep(1:okresy_czasu, times = n),\n  interwencja = rep(sample(c(0, 1), n, replace = TRUE), each = okresy_czasu),\n  wynik = NA\n)\n\n# Generowanie wyników\npanel_data$wynik &lt;- with(panel_data,\n                         10 + 2 * czas + 5 * interwencja + 3 * (czas &gt;= 3 & interwencja == 1) + rnorm(n * okresy_czasu, 0, 2))\n\n# Estymacja modelu DiD\ndid_model &lt;- plm(wynik ~ interwencja * factor(czas), \n                 data = panel_data, \n                 index = c(\"id\", \"czas\"), \n                 model = \"within\")\n\n# Podsumowanie wyników\nsummary(did_model)\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = wynik ~ interwencja * factor(czas), data = panel_data, \n    model = \"within\", index = c(\"id\", \"czas\"))\n\nBalanced Panel: n = 1000, T = 5, N = 5000\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-5.932194 -1.200686 -0.033411  1.236533  6.439693 \n\nCoefficients:\n                           Estimate Std. Error t-value Pr(&gt;|t|)    \nfactor(czas)2              2.077222   0.124505 16.6838   &lt;2e-16 ***\nfactor(czas)3              4.161871   0.124505 33.4273   &lt;2e-16 ***\nfactor(czas)4              5.960653   0.124505 47.8748   &lt;2e-16 ***\nfactor(czas)5              8.164066   0.124505 65.5722   &lt;2e-16 ***\ninterwencja:factor(czas)2 -0.020059   0.180272 -0.1113   0.9114    \ninterwencja:factor(czas)3  2.688227   0.180272 14.9121   &lt;2e-16 ***\ninterwencja:factor(czas)4  3.084521   0.180272 17.1104   &lt;2e-16 ***\ninterwencja:factor(czas)5  2.867242   0.180272 15.9051   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    78894\nResidual Sum of Squares: 16182\nR-Squared:      0.79489\nAdj. R-Squared: 0.74315\nF-statistic: 1933.82 on 8 and 3992 DF, p-value: &lt; 2.22e-16\n\n# Wizualizacja DiD\nggplot(panel_data, aes(x = czas, y = wynik, color = factor(interwencja), group = interwencja)) +\n  stat_summary(fun = mean, geom = \"line\", size = 1) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  geom_vline(xintercept = 3, linetype = \"dashed\", color = \"gray50\") +\n  labs(title = \"Analiza Różnicy w Różnicach\",\n       x = \"Czas\", y = \"Wynik\", color = \"Interwencja\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\", labels = c(\"Kontrola\", \"Interwencja\"))\n\n\n\n\nAnaliza Różnicy w Różnicach\n\n\n\n\nWykres pokazuje średnie wyniki dla grup interwencji i kontrolnej w czasie. Pionowa przerywana linia wskazuje punkt interwencji. Oszacowanie DiD to różnica między zmianami obu grup od okresu przed do po interwencji.\n\n\n8.4.2.2 Regresja Nieciągła (RDD)\nRDD jest stosowana, gdy przydział do interwencji jest określony przez wartość graniczną na ciągłej zmiennej. Porównuje obserwacje tuż powyżej i poniżej punktu granicznego, aby oszacować efekt interwencji.\nPrzeprowadźmy analizę RDD przy użyciu pakietu rdrobust:\n\nlibrary(rdrobust)\n\n# Generowanie syntetycznych danych RDD\nset.seed(202)\nn &lt;- 1000\nx &lt;- runif(n, -1, 1)\ny &lt;- 3 + 2 * x + 4 * (x &gt;= 0) + rnorm(n, 0, 1)\n\nrdd_data &lt;- data.frame(x, y)\n\n# Analiza RDD\nrdd_result &lt;- rdrobust(y, x, c = 0)\nsummary(rdd_result)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1000\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  499          501\nEff. Number of Obs.             182          175\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   0.362        0.362\nBW bias (b)                   0.575        0.575\nrho (h/b)                     0.630        0.630\nUnique Obs.                     499          501\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     4.092     0.231    17.723     0.000     [3.640 , 4.545]     \n        Robust         -         -    15.013     0.000     [3.600 , 4.680]     \n=============================================================================\n\n# Wizualizacja RDD\nggplot(rdd_data, aes(x = x, y = y)) +\n  geom_point(alpha = 0.4) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(data = subset(rdd_data, x &lt; 0), method = \"lm\", se = FALSE, color = \"blue\") +\n  geom_smooth(data = subset(rdd_data, x &gt;= 0), method = \"lm\", se = FALSE, color = \"green\") +\n  labs(title = \"Regresja Nieciągła\",\n       x = \"Zmienna Bieżąca\", y = \"Wynik\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nAnaliza Regresji Nieciągłej\n\n\n\n\nWykres pokazuje nieciągłość w punkcie granicznym (x = 0), z oddzielnymi liniami regresji dopasowanymi po obu stronach. Efekt interwencji jest szacowany przez różnicę między tymi liniami w punkcie granicznym.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#model-potencjalnych-wyników-neymana-rubina",
    "href": "rozdzial4.html#model-potencjalnych-wyników-neymana-rubina",
    "title": "8  Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne",
    "section": "8.5 Model Potencjalnych Wyników Neymana-Rubina",
    "text": "8.5 Model Potencjalnych Wyników Neymana-Rubina\nModel potencjalnych wyników Neymana-Rubina zapewnia formalne podejście do wnioskowania przyczynowego. Wprowadza on koncepcję potencjalnych wyników: dla każdej jednostki rozważamy wynik w warunkach interwencji i w warunkach kontrolnych, mimo że w rzeczywistości możemy zaobserwować tylko jeden z nich.\nKluczowe pojęcia:\n\nPotencjalne Wyniki: \\(Y_i(1)\\) i \\(Y_i(0)\\) odpowiednio dla interwencji i kontroli.\nObserwowany Wynik: \\(Y_i = Y_i(1)T_i + Y_i(0)(1-T_i)\\), gdzie \\(T_i\\) to wskaźnik interwencji.\nIndywidualny Efekt Interwencji: \\(\\tau_i = Y_i(1) - Y_i(0)\\)\nPrzeciętny Efekt Interwencji (ATE): \\(E[\\tau_i] = E[Y_i(1) - Y_i(0)]\\)\n\nModel podkreśla “fundamentalny problem wnioskowania przyczynowego”: nigdy nie możemy zaobserwować obu potencjalnych wyników dla pojedynczej jednostki jednocześnie.\n\n8.5.1 Przykład: Szacowanie ATE w RCT\nW RCT, losowy przydział zapewnia, że interwencja jest niezależna od potencjalnych wyników, umożliwiając nieobciążone oszacowanie ATE:\n\\[\n\\hat{ATE} = \\frac{1}{n_1} \\sum_{i:T_i=1} Y_i - \\frac{1}{n_0} \\sum_{i:T_i=0} Y_i\n\\]\nGdzie \\(n_1\\) i \\(n_0\\) to odpowiednio liczby jednostek w grupie interwencji i kontrolnej.\n\n# Używając danych RCT z wcześniejszego przykładu\nate_estimate &lt;- mean(data$post_test[data$grupa == \"Eksperymentalna\"]) - \n                mean(data$post_test[data$grupa == \"Kontrolna\"])\n\ncat(\"Oszacowany Przeciętny Efekt Interwencji:\", round(ate_estimate, 2))\n\nOszacowany Przeciętny Efekt Interwencji: 9.66",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne</span>"
    ]
  },
  {
    "objectID": "chapter4.html#conclusion-1",
    "href": "chapter4.html#conclusion-1",
    "title": "7  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "7.5 Conclusion",
    "text": "7.5 Conclusion\nThis chapter has explored various research designs, from experimental approaches like RCTs and factorial designs to non-experimental methods such as observational studies and quasi-experimental designs. We’ve demonstrated how to implement and visualize these designs using R, and introduced the Neyman-Rubin potential outcome framework for causal inference.\nUnderstanding these designs and their appropriate use is crucial for conducting rigorous research and drawing valid causal conclusions. Each design has its strengths and limitations, and the choice of design should be guided by the research question, ethical considerations, and practical constraints.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "rozdzial4.html#testy-ab-przykład-i-porównanie-z-rct",
    "href": "rozdzial4.html#testy-ab-przykład-i-porównanie-z-rct",
    "title": "8  Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne",
    "section": "8.3 Testy A/B: Przykład i Porównanie z RCT",
    "text": "8.3 Testy A/B: Przykład i Porównanie z RCT\nTesty A/B to szeroko stosowana metoda eksperymentalna w marketingu cyfrowym, projektowaniu doświadczeń użytkownika i rozwoju produktów. Ten rozdział przedstawi przykład testu A/B, wyjaśni jego metodologię i omówi, czym różni się od Randomizowanych Badań Kontrolowanych (RCT).\n\n8.3.1 Przykład: Współczynnik Konwersji Strony Docelowej\nRozważmy przykład, w którym firma e-commerce chce poprawić współczynnik konwersji swojej strony docelowej. Decydują się przetestować dwa różne układy: obecny układ (A) i nowy układ (B).\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nset.seed(123)\n\n# Symulacja danych\nn_odwiedzajacych &lt;- 10000\ndane &lt;- data.frame(\n  Wersja = sample(c(\"A\", \"B\"), n_odwiedzajacych, replace = TRUE),\n  Konwersja = rbinom(n_odwiedzajacych, 1, ifelse(sample(c(\"A\", \"B\"), n_odwiedzajacych, replace = TRUE) == \"A\", 0.10, 0.12))\n)\n\n# Obliczenie współczynników konwersji\nwspolczynniki_konwersji &lt;- dane %&gt;%\n  group_by(Wersja) %&gt;%\n  summarise(\n    Odwiedzajacy = n(),\n    Konwersje = sum(Konwersja),\n    WspolczynnikKonwersji = mean(Konwersja)\n  )\n\n# Wizualizacja wyników\nggplot(wspolczynniki_konwersji, aes(x = Wersja, y = WspolczynnikKonwersji, fill = Wersja)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = sprintf(\"%.2f%%\", WspolczynnikKonwersji * 100)), \n            vjust = -0.5, size = 4) +\n  theme_minimal() +\n  labs(title = \"Test A/B: Współczynniki Konwersji Strony Docelowej\",\n       x = \"Wersja Strony\", y = \"Współczynnik Konwersji\") +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 0.15)) +\n  scale_fill_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\nFigure 8.1: Wyniki Testu A/B: Współczynniki Konwersji Strony Docelowej\n\n\n\n\n\nW tym przykładzie zasymulowaliśmy dane dla 10 000 odwiedzających losowo przypisanych do wersji A lub B strony docelowej. Wyniki pokazują, że wersja B ma nieco wyższy współczynnik konwersji (12,02%) w porównaniu do wersji A (10,08%).\n\n\n8.3.2 Metodologia Testów A/B\nTesty A/B zazwyczaj przebiegają według następujących kroków:\n\nZidentyfikowanie elementu do przetestowania (np. układ strony docelowej).\nStworzenie dwóch wersji: kontrolnej (A) i wariantu (B).\nLosowe przypisanie odwiedzających do jednej z wersji.\nZbieranie danych o interesującej nas metryce (np. współczynniku konwersji).\nAnaliza wyników przy użyciu metod statystycznych.\nPodjęcie decyzji na podstawie wyników.\n\n\n\n8.3.3 Różnice między Testami A/B a RCT\nChoć testy A/B i Randomizowane Badania Kontrolowane (RCT) mają pewne podobieństwa, istnieje kilka kluczowych różnic:\n\nZakres i Kontekst:\n\nTesty A/B: Zazwyczaj stosowane w środowiskach cyfrowych do szybkich, iteracyjnych ulepszeń.\nRCT: Stosowane w różnych dziedzinach, w tym medycynie, psychologii i naukach społecznych, często dla bardziej złożonych interwencji.\n\nCzas Trwania:\n\nTesty A/B: Zwykle krótsze, często trwające dni lub tygodnie.\nRCT: Mogą trwać miesiące lub lata, szczególnie w badaniach medycznych.\n\nWielkość Próby:\n\nTesty A/B: Mogą obejmować bardzo duże próby ze względu na łatwość implementacji na platformach cyfrowych.\nRCT: Wielkości prób są często mniejsze ze względu na praktyczne i kosztowe ograniczenia.\n\nZaślepienie:\n\nTesty A/B: Uczestnicy zazwyczaj nie są świadomi, że biorą udział w teście.\nRCT: Mogą obejmować pojedyncze, podwójne lub potrójne zaślepienie w celu zmniejszenia błędu systematycznego.\n\nWzględy Etyczne:\n\nTesty A/B: Generalnie obejmują zmiany niskiego ryzyka z minimalnymi obawami etycznymi.\nRCT: Często wymagają obszernej oceny etycznej, szczególnie w kontekście medycznym.\n\nMiary Wyników:\n\nTesty A/B: Zazwyczaj skupiają się na pojedynczym, łatwo mierzalnym wyniku (np. współczynnik klikalności).\nRCT: Często mierzą wiele wyników, w tym potencjalne skutki uboczne lub długoterminowe efekty.\n\nMożliwość Uogólnienia:\n\nTesty A/B: Wyniki są często specyficzne dla testowanej platformy lub kontekstu.\nRCT: Dążą do szerszej możliwości uogólnienia, choć może to się różnić.\n\nZłożoność Analizy:\n\nTesty A/B: Często wykorzystują prostsze analizy statystyczne.\nRCT: Mogą obejmować bardziej złożone metody statystyczne, aby uwzględnić różne czynniki.\n\n\nTesty A/B są potężnym narzędziem do podejmowania decyzji opartych na danych w środowiskach cyfrowych. Choć dzielą podstawową zasadę randomizacji z RCT, są zazwyczaj prostsze, szybsze i bardziej skoncentrowane na konkretnych, mierzalnych wynikach w kontekstach cyfrowych. Zrozumienie tych różnic pomaga badaczom i praktykom wybrać najbardziej odpowiednią metodę do ich konkretnych potrzeb i ograniczeń.\nTesty A/B są szczególnie przydatne w optymalizacji stron internetowych, aplikacji mobilnych i kampanii marketingowych, gdzie szybkie iteracje i ciągłe ulepszenia są kluczowe. Z kolei RCT pozostają złotym standardem w badaniach naukowych, szczególnie w dziedzinach takich jak medycyna, gdzie rygorystyczna kontrola i długoterminowa obserwacja są niezbędne.\nNiezależnie od wybranej metody, kluczowe jest staranne planowanie, precyzyjne wykonanie i ostrożna interpretacja wyników. Zarówno testy A/B, jak i RCT, gdy są odpowiednio stosowane, mogą dostarczyć cennych informacji i przyczynić się do podejmowania lepszych decyzji opartych na danych.\n\n\n8.3.4 Przykład 1: Wpływ Długości Snu na Wydajność Poznawczą\nPytanie Badawcze: Czy zwiększenie długości snu poprawia wydajność poznawczą u studentów?\n\n# Generowanie przykładowych danych\nset.seed(456)\nn &lt;- 100\npre_eksperymentalna &lt;- rnorm(n, mean = 70, sd = 10)\npost_eksperymentalna &lt;- pre_eksperymentalna + rnorm(n, mean = 8, sd = 5)\npre_kontrolna &lt;- rnorm(n, mean = 70, sd = 10)\npost_kontrolna &lt;- pre_kontrolna + rnorm(n, mean = 1, sd = 5)\n\ndane &lt;- data.frame(\n  Grupa = rep(c(\"Eksperymentalna\", \"Kontrolna\"), each = n*2),\n  Czas = rep(rep(c(\"Przed\", \"Po\"), each = n), 2),\n  Wynik = c(pre_eksperymentalna, post_eksperymentalna, pre_kontrolna, post_kontrolna)\n)\n\n# Tworzenie wykresu\nggplot(dane, aes(x = Czas, y = Wynik, color = Grupa, group = Grupa)) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Wpływ Zwiększonej Długości Snu na Wydajność Poznawczą\") +\n  xlab(\"Czas\") +\n  ylab(\"Wynik Wydajności Poznawczej\")\n\n\n\n\n\n\n\nFigure 8.2: Wpływ Długości Snu na Wydajność Poznawczą\n\n\n\n\n\n\n8.3.4.1 Interpretacja\nTen wykres pokazuje wpływ zwiększonej długości snu na wydajność poznawczą. Grupa eksperymentalna, która zwiększyła długość snu, wykazuje znacznie większą poprawę w wydajności poznawczej w porównaniu do grupy kontrolnej. Sugeruje to, że zwiększenie długości snu może pozytywnie wpływać na zdolności poznawcze studentów.\n\n\n\n8.3.5 Przykład 2: Wpływ Treningu Uważności na Poziom Stresu\nPytanie Badawcze: Czy krótkoterminowy program treningu uważności może obniżyć poziom stresu u pracowników służby zdrowia?\n\n# Generowanie przykładowych danych\nset.seed(789)\nn &lt;- 120\npre_eksperymentalna &lt;- rnorm(n, mean = 60, sd = 15)\npost_eksperymentalna &lt;- pre_eksperymentalna + rnorm(n, mean = -12, sd = 8)\npre_kontrolna &lt;- rnorm(n, mean = 60, sd = 15)\npost_kontrolna &lt;- pre_kontrolna + rnorm(n, mean = -2, sd = 6)\n\ndane &lt;- data.frame(\n  Grupa = rep(c(\"Uważność\", \"Kontrolna\"), each = n*2),\n  Czas = rep(rep(c(\"Przed\", \"Po\"), each = n), 2),\n  PoziomStresu = c(pre_eksperymentalna, post_eksperymentalna, pre_kontrolna, post_kontrolna)\n)\n\n# Tworzenie wykresu\nggplot(dane, aes(x = Czas, y = PoziomStresu, color = Grupa, group = Grupa)) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Wpływ Treningu Uważności na Poziom Stresu\") +\n  xlab(\"Czas\") +\n  ylab(\"Poziom Stresu\")\n\n\n\n\n\n\n\nFigure 8.3: Wpływ Treningu Uważności na Poziom Stresu\n\n\n\n\n\n\n8.3.5.1 Interpretacja\nTa wizualizacja ilustruje wpływ programu treningu uważności na poziom stresu u pracowników służby zdrowia. Grupa uważności wykazuje znacznie większy spadek poziomu stresu w porównaniu do grupy kontrolnej. Sugeruje to, że program treningu uważności może być skuteczny w redukcji poziomu stresu wśród pracowników służby zdrowia.\n\n\n\n8.3.6 Projekty Czynnikowe\nProjekty czynnikowe pozwalają badaczom na jednoczesne badanie efektów wielu zmiennych niezależnych. Są one efektywne i mogą ujawniać efekty interakcji między zmiennymi.\nPrzykład projektu czynnikowego 2x2:\n\n# Tworzenie przykładowych danych dla projektu czynnikowego 2x2\nset.seed(456)\nn_per_group &lt;- 25\n\nfactorial_data &lt;- data.frame(\n  czynnik_a = rep(rep(c(\"Niski\", \"Wysoki\"), each = n_per_group), 2),\n  czynnik_b = rep(c(\"Kontrola\", \"Interwencja\"), each = n_per_group * 2),\n  wynik = NA\n)\n\n# Generowanie wyników\nfactorial_data$wynik &lt;- ifelse(factorial_data$czynnik_a == \"Niski\" & factorial_data$czynnik_b == \"Kontrola\",\n                               rnorm(n_per_group, 40, 5),\n                               ifelse(factorial_data$czynnik_a == \"Niski\" & factorial_data$czynnik_b == \"Interwencja\",\n                                      rnorm(n_per_group, 45, 5),\n                                      ifelse(factorial_data$czynnik_a == \"Wysoki\" & factorial_data$czynnik_b == \"Kontrola\",\n                                             rnorm(n_per_group, 50, 5),\n                                             rnorm(n_per_group, 60, 5))))\n\n# Tworzenie wykresu\nggplot(factorial_data, aes(x = czynnik_b, y = wynik, fill = czynnik_a)) +\n  geom_boxplot() +\n  facet_wrap(~czynnik_a, scales = \"free_x\") +\n  labs(title = \"Projekt Czynnikowy 2x2\",\n       x = \"Czynnik B\", y = \"Wynik\", fill = \"Czynnik A\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\nProjekt Czynnikowy 2x2\n\n\n\n\nTen wykres ilustruje projekt czynnikowy 2x2, pokazując efekty dwóch czynników (A i B) na zmienną wynikową. Możemy zaobserwować główne efekty dla obu czynników oraz potencjalny efekt interakcji.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne</span>"
    ]
  },
  {
    "objectID": "chapter4.html#ab-testing-an-example-and-comparison-with-rcts",
    "href": "chapter4.html#ab-testing-an-example-and-comparison-with-rcts",
    "title": "9  Research Designs: Experimental and Non-Experimental Approaches",
    "section": "9.3 A/B Testing: An Example and Comparison with RCTs",
    "text": "9.3 A/B Testing: An Example and Comparison with RCTs\nA/B testing is a widely used experimental method in digital marketing, user experience design, and product development. This chapter will present an example of A/B testing, explain its methodology, and discuss how it differs from Randomized Controlled Trials (RCTs).\n\n9.3.1 Example: Website Landing Page Conversion Rate\nLet’s consider an example where an e-commerce company wants to improve the conversion rate of their landing page. They decide to test two different layouts: the current layout (A) and a new layout (B).\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nset.seed(123)\n\n# Simulate data\nn_visitors &lt;- 10000\ndata &lt;- data.frame(\n  Version = sample(c(\"A\", \"B\"), n_visitors, replace = TRUE),\n  Converted = rbinom(n_visitors, 1, ifelse(sample(c(\"A\", \"B\"), n_visitors, replace = TRUE) == \"A\", 0.10, 0.12))\n)\n\n# Calculate conversion rates\nconversion_rates &lt;- data %&gt;%\n  group_by(Version) %&gt;%\n  summarise(\n    Visitors = n(),\n    Conversions = sum(Converted),\n    ConversionRate = mean(Converted)\n  )\n\n# Visualize results\nggplot(conversion_rates, aes(x = Version, y = ConversionRate, fill = Version)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = sprintf(\"%.2f%%\", ConversionRate * 100)), \n            vjust = -0.5, size = 4) +\n  theme_minimal() +\n  labs(title = \"A/B Test: Landing Page Conversion Rates\",\n       x = \"Page Version\", y = \"Conversion Rate\") +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 0.15)) +\n  scale_fill_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\nFigure 9.1: A/B Test Results: Landing Page Conversion Rates\n\n\n\n\n\nIn this example, we simulated data for 10,000 visitors randomly assigned to either version A or B of the landing page. The results show that version B has a slightly higher conversion rate (12.02%) compared to version A (10.08%).\n\n\n9.3.2 A/B Testing Methodology\nA/B testing typically follows these steps:\n\nIdentify the element to be tested (e.g., landing page layout).\nCreate two versions: the control (A) and the variant (B).\nRandomly assign visitors to either version.\nCollect data on the metric of interest (e.g., conversion rate).\nAnalyze the results using statistical methods.\nMake a decision based on the results.\n\n\n\n9.3.3 Differences between A/B Testing and RCTs\nWhile A/B testing and Randomized Controlled Trials (RCTs) share some similarities, they have several key differences:\n\nScope and Context:\n\nA/B Testing: Typically used in digital environments for quick, iterative improvements.\nRCTs: Used in various fields, including medicine, psychology, and social sciences, often for more complex interventions.\n\nDuration:\n\nA/B Testing: Usually shorter, often running for days or weeks.\nRCTs: Can last months or years, especially in medical research.\n\nSample Size:\n\nA/B Testing: Can involve very large sample sizes due to ease of implementation in digital platforms.\nRCTs: Sample sizes are often smaller due to practical and cost constraints.\n\nBlinding:\n\nA/B Testing: Participants are usually unaware they’re part of a test.\nRCTs: May involve single, double, or triple blinding to reduce bias.\n\nEthical Considerations:\n\nA/B Testing: Generally involves low-risk changes with minimal ethical concerns.\nRCTs: Often require extensive ethical review, especially in medical contexts.\n\nOutcome Measures:\n\nA/B Testing: Typically focuses on a single, easily measurable outcome (e.g., click-through rate).\nRCTs: Often measure multiple outcomes, including potential side effects or long-term impacts.\n\nGeneralizability:\n\nA/B Testing: Results are often specific to the platform or context tested.\nRCTs: Aim for broader generalizability, though this can vary.\n\nAnalysis Complexity:\n\nA/B Testing: Often uses simpler statistical analyses.\nRCTs: May involve more complex statistical methods to account for various factors.\n\n\nA/B testing is a powerful tool for making data-driven decisions in digital environments. While it shares the fundamental principle of randomization with RCTs, it is typically simpler, faster, and more focused on specific, measurable outcomes in digital contexts. Understanding these differences helps researchers and practitioners choose the most appropriate method for their specific needs and constraints.\n\n\n9.3.4 Example 1: Effect of Sleep Duration on Cognitive Performance\nResearch Question: Does increasing sleep duration improve cognitive performance in college students?\n\n# Generating sample data\nset.seed(456)\nn &lt;- 100\npre_experimental &lt;- rnorm(n, mean = 70, sd = 10)\npost_experimental &lt;- pre_experimental + rnorm(n, mean = 8, sd = 5)\npre_control &lt;- rnorm(n, mean = 70, sd = 10)\npost_control &lt;- pre_control + rnorm(n, mean = 1, sd = 5)\n\ndata &lt;- data.frame(\n  Group = rep(c(\"Experimental\", \"Control\"), each = n*2),\n  Time = rep(rep(c(\"Pre\", \"Post\"), each = n), 2),\n  Score = c(pre_experimental, post_experimental, pre_control, post_control)\n)\n\n# Creating the plot\nggplot(data, aes(x = Time, y = Score, color = Group, group = Group)) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Effect of Increased Sleep Duration on Cognitive Performance\") +\n  xlab(\"Time\") +\n  ylab(\"Cognitive Performance Score\")\n\n\n\n\n\n\n\nFigure 9.2: Effect of Sleep Duration on Cognitive Performance\n\n\n\n\n\n\n9.3.4.1 Interpretation\nThis plot demonstrates the effect of increased sleep duration on cognitive performance. The experimental group, which increased their sleep duration, shows a more substantial improvement in cognitive performance compared to the control group. This suggests that increasing sleep duration may positively impact cognitive abilities in college students.\n\n\n\n9.3.5 Example 2: Impact of Mindfulness Training on Stress Levels\nResearch Question: Can a short-term mindfulness training program reduce stress levels in healthcare workers?\n\n# Generating sample data\nset.seed(789)\nn &lt;- 120\npre_experimental &lt;- rnorm(n, mean = 60, sd = 15)\npost_experimental &lt;- pre_experimental + rnorm(n, mean = -12, sd = 8)\npre_control &lt;- rnorm(n, mean = 60, sd = 15)\npost_control &lt;- pre_control + rnorm(n, mean = -2, sd = 6)\n\ndata &lt;- data.frame(\n  Group = rep(c(\"Mindfulness\", \"Control\"), each = n*2),\n  Time = rep(rep(c(\"Pre\", \"Post\"), each = n), 2),\n  StressScore = c(pre_experimental, post_experimental, pre_control, post_control)\n)\n\n# Creating the plot\nggplot(data, aes(x = Time, y = StressScore, color = Group, group = Group)) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  theme_minimal() +\n  ggtitle(\"Impact of Mindfulness Training on Stress Levels\") +\n  xlab(\"Time\") +\n  ylab(\"Stress Score\")\n\n\n\n\n\n\n\nFigure 9.3: Impact of Mindfulness Training on Stress Levels\n\n\n\n\n\n\n9.3.5.1 Interpretation\nThis visualization illustrates the impact of a mindfulness training program on stress levels in healthcare workers. The mindfulness group shows a more significant decrease in stress scores compared to the control group. This suggests that the mindfulness training program may be effective in reducing stress levels among healthcare workers.\nWhen interpreting such results, it’s important to consider:\n\nThe magnitude of the change in each group\nThe difference in change between the experimental and control groups\nThe variability within each group\nAny potential confounding factors not accounted for in the experimental design\n\nThese examples provide a template for visualizing and interpreting similar experimental designs across different research contexts.\n\n\n\n9.3.6 Factorial Designs\nFactorial designs allow researchers to study the effects of multiple independent variables simultaneously. They are efficient and can reveal interaction effects between variables.\nExample of a 2x2 factorial design:\n\n# Create sample data for 2x2 factorial design\nset.seed(456)\nn_per_group &lt;- 25\n\nfactorial_data &lt;- data.frame(\n  factor_a = rep(rep(c(\"Low\", \"High\"), each = n_per_group), 2),\n  factor_b = rep(c(\"Control\", \"Treatment\"), each = n_per_group * 2),\n  outcome = NA\n)\n\n# Generate outcomes\nfactorial_data$outcome &lt;- ifelse(factorial_data$factor_a == \"Low\" & factorial_data$factor_b == \"Control\",\n                                 rnorm(n_per_group, 40, 5),\n                                 ifelse(factorial_data$factor_a == \"Low\" & factorial_data$factor_b == \"Treatment\",\n                                        rnorm(n_per_group, 45, 5),\n                                        ifelse(factorial_data$factor_a == \"High\" & factorial_data$factor_b == \"Control\",\n                                               rnorm(n_per_group, 50, 5),\n                                               rnorm(n_per_group, 60, 5))))\n\n# Create plot\nggplot(factorial_data, aes(x = factor_b, y = outcome, fill = factor_a)) +\n  geom_boxplot() +\n  facet_wrap(~factor_a, scales = \"free_x\") +\n  labs(title = \"2x2 Factorial Design\",\n       x = \"Factor B\", y = \"Outcome\", fill = \"Factor A\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n2x2 Factorial Design\n\n\n\n\nThis plot illustrates a 2x2 factorial design, showing the effects of two factors (A and B) on the outcome variable. We can observe main effects for both factors and a potential interaction effect.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Designs: Experimental and Non-Experimental Approaches</span>"
    ]
  },
  {
    "objectID": "chapter3b.html",
    "href": "chapter3b.html",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "",
    "text": "7.1 Defining Reliability and Validity\nReliability refers to the consistency of a measure. A reliable measurement or study produces similar results under consistent conditions.\nValidity refers to the accuracy of a measure. A valid measurement or study accurately represents what it claims to measure.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#the-four-combinations-of-reliability-and-validity",
    "href": "chapter3b.html#the-four-combinations-of-reliability-and-validity",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.2 The Four Combinations of Reliability and Validity",
    "text": "7.2 The Four Combinations of Reliability and Validity\nThere are four possible combinations of reliability and validity:\n\nHigh Reliability, High Validity\nHigh Reliability, Low Validity\nLow Reliability, High Validity\nLow Reliability, Low Validity\n\nLet’s explore each of these combinations with examples and visualizations.\n\n7.2.1 1. High Reliability, High Validity\nThis is the ideal scenario in research. Measurements are both consistent and accurate.\nExample: A well-calibrated digital scale used to measure weight. It consistently gives the same reading for the same object and accurately represents the true weight.\n\n\n7.2.2 2. High Reliability, Low Validity\nIn this case, measurements are consistent but not accurate.\nExample: A miscalibrated scale that always measures 5 kg too heavy. It gives consistent results (high reliability) but doesn’t represent the true weight (low validity).\n\n\n7.2.3 3. Low Reliability, High Validity\nHere, measurements are accurate on average but inconsistent.\nExample: A scale that fluctuates around the true weight. Sometimes it’s a bit over, sometimes a bit under, but on average, it’s correct.\n\n\n7.2.4 4. Low Reliability, Low Validity\nThis is the worst-case scenario, where measurements are neither consistent nor accurate.\nExample: A broken scale that gives random readings unrelated to the true weight.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#visualizing-reliability-and-validity",
    "href": "chapter3b.html#visualizing-reliability-and-validity",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.3 Visualizing Reliability and Validity",
    "text": "7.3 Visualizing Reliability and Validity\nTo better understand these concepts, let’s create visualizations using ggplot2 in R. We’ll simulate measurement data for each scenario and plot them.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(patchwork)\n\nset.seed(123)\n\n# Generate data for each scenario\nn &lt;- 100\ntrue_value &lt;- 50\n\ndata &lt;- tibble(\n  high_rel_high_val = rnorm(n, mean = true_value, sd = 1),\n  high_rel_low_val = rnorm(n, mean = true_value + 5, sd = 1),\n  low_rel_high_val = rnorm(n, mean = true_value, sd = 5),\n  low_rel_low_val = runif(n, min = 0, max = 100)\n) %&gt;%\n  mutate(id = row_number()) %&gt;%\n  pivot_longer(cols = -id, names_to = \"scenario\", values_to = \"measurement\")\n\n# Create the scatterplot\nscatter_plot &lt;- ggplot(data, aes(x = id, y = measurement, color = scenario)) +\n  geom_point(alpha = 0.6, size = 2) +\n  geom_hline(yintercept = true_value, linetype = \"dashed\", color = \"black\", size = 1) +\n  facet_wrap(~ scenario, ncol = 2, scales = \"free_y\",\n             labeller = labeller(scenario = c(\n               \"high_rel_high_val\" = \"High Reliability, High Validity\",\n               \"high_rel_low_val\" = \"High Reliability, Low Validity\",\n               \"low_rel_high_val\" = \"Low Reliability, High Validity\",\n               \"low_rel_low_val\" = \"Low Reliability, Low Validity\"\n             ))) +\n  labs(title = \"Scatterplots of Measurements\",\n       subtitle = \"Dashed line represents the true value\",\n       x = \"Measurement ID\",\n       y = \"Measured Value\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\",\n        strip.text = element_text(size = 16, face = \"bold\"),\n        plot.title = element_text(size = 20, face = \"bold\"),\n        plot.subtitle = element_text(size = 16))\n\n# Create the histogram\nhist_plot &lt;- ggplot(data, aes(x = measurement, fill = scenario)) +\n  geom_histogram(bins = 20, alpha = 0.7) +\n  geom_vline(xintercept = true_value, color = \"red\", linetype = \"dashed\", size = 1) +\n  facet_wrap(~ scenario, ncol = 2, scales = \"free\",\n             labeller = labeller(scenario = c(\n               \"high_rel_high_val\" = \"High Reliability, High Validity\",\n               \"high_rel_low_val\" = \"High Reliability, Low Validity\",\n               \"low_rel_high_val\" = \"Low Reliability, High Validity\",\n               \"low_rel_low_val\" = \"Low Reliability, Low Validity\"\n             ))) +\n  labs(title = \"Histograms of Measurements\",\n       subtitle = \"Red dashed line represents the true value\",\n       x = \"Measured Value\",\n       y = \"Count\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\",\n        strip.text = element_text(size = 16, face = \"bold\"),\n        plot.title = element_text(size = 20, face = \"bold\"),\n        plot.subtitle = element_text(size = 16))\n\n# Combine the plots\ncombined_plot &lt;- scatter_plot / hist_plot +\n  plot_layout(heights = c(1, 1)) +\n  plot_annotation(\n    title = \"Reliability and Validity in Measurements\",\n    theme = theme(plot.title = element_text(hjust = 0.5, size = 24, face = \"bold\"))\n  )\n\n# Display the combined plot\ncombined_plot\n\n\n\n\n\n\n\n\n\n7.3.1 Interpreting the Visualizations\n\nHigh Reliability, High Validity: Points cluster tightly around the true value (dashed line).\nHigh Reliability, Low Validity: Points cluster tightly, but consistently above the true value.\nLow Reliability, High Validity: Points scatter widely but center around the true value.\nLow Reliability, Low Validity: Points scatter randomly with no clear pattern or relation to the true value.\n\nUnderstanding reliability and validity is crucial in data science and research. High reliability ensures consistent measurements, while high validity ensures accurate representations of what we intend to measure. By considering both aspects, researchers can design more robust studies and draw more meaningful conclusions from their data.\nWhen conducting your own research or analyzing others’ work, always consider: - How reliable are the measurements? - How valid is the approach for measuring the intended concept? - Do the methods used support both reliability and validity?\nBy keeping these questions in mind, you’ll be better equipped to produce and interpret high-quality research in data science.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#conclusion",
    "href": "chapter3b.html#conclusion",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.4 Conclusion",
    "text": "7.4 Conclusion\nUnderstanding reliability and validity is crucial in data science and research. High reliability ensures consistent measurements, while high validity ensures accurate representations of what we intend to measure. By considering both aspects, researchers can design more robust studies and draw more meaningful conclusions from their data.\nWhen conducting your own research or analyzing others’ work, always consider: - How reliable are the measurements? - How valid is the approach for measuring the intended concept? - Do the methods used support both reliability and validity?\nBy keeping these questions in mind, you’ll be better equipped to produce and interpret high-quality research in data science.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#types-of-reliability",
    "href": "chapter3b.html#types-of-reliability",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.4 Types of Reliability",
    "text": "7.4 Types of Reliability\nReliability can be assessed in several ways, each focusing on a different aspect of consistency:\n\nTest-Retest Reliability: This measures the consistency of a test over time. It involves administering the same test to the same group of participants at different times and comparing the results.\nInter-Rater Reliability: This assesses the degree of agreement among different raters or observers. It’s crucial when subjective judgments are involved in data collection.\nInternal Consistency: This evaluates how well different items on a test or scale measure the same construct. Cronbach’s alpha is a common measure of internal consistency.\nParallel Forms Reliability: This involves creating two equivalent forms of a test and administering them to the same group. The correlation between the two sets of scores indicates reliability.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#types-of-validity",
    "href": "chapter3b.html#types-of-validity",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.5 Types of Validity",
    "text": "7.5 Types of Validity\nValidity is a multifaceted concept, with several types that researchers need to consider:\n\nContent Validity: This ensures that a measure covers all aspects of the construct it aims to measure. It’s often assessed by expert judgment.\nConstruct Validity: This evaluates whether a test measures the intended theoretical construct. It includes:\n\nConvergent Validity: The degree to which the measure correlates with other measures of the same construct.\nDiscriminant Validity: The extent to which the measure does not correlate with measures of different constructs.\n\nCriterion Validity: This assesses how well a measure predicts an outcome. It includes:\n\nConcurrent Validity: How well the measure correlates with other measures of the same construct at the same time.\nPredictive Validity: How well the measure predicts future outcomes.\n\nFace Validity: This refers to whether a test appears to measure what it claims to measure. While not a scientific measure, it can be important for participant buy-in.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#internal-vs.-external-validity",
    "href": "chapter3b.html#internal-vs.-external-validity",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.6 Internal vs. External Validity",
    "text": "7.6 Internal vs. External Validity\nThese concepts are crucial in experimental design and the generalizability of research findings:\n\n7.6.1 Internal Validity\nInternal validity refers to the extent to which a study establishes a causal relationship between the independent and dependent variables. It answers the question: “Did the experimental treatment actually cause the observed effects?”\nFactors that can threaten internal validity include: - History: External events occurring between pre-test and post-test - Maturation: Natural changes in participants over time - Testing effects: Changes due to taking a pre-test - Instrumentation: Changes in the measurement tool or observers - Selection bias: Non-random assignment to groups - Attrition: Loss of participants during the study\n\n\n7.6.2 External Validity\nExternal validity refers to the extent to which the results of a study can be generalized to other situations, populations, or settings. It addresses the question: “To what extent can the findings be applied beyond the specific context of the study?”\nFactors that can affect external validity include: - Population validity: How well the sample represents the larger population - Ecological validity: How well the study setting represents real-world conditions - Temporal validity: Whether the results hold true across time",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#consistency-in-research",
    "href": "chapter3b.html#consistency-in-research",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.7 Consistency in Research",
    "text": "7.7 Consistency in Research\nConsistency is closely related to reliability but extends beyond just measurement. In research, consistency refers to the overall coherence and stability of results across different contexts, methods, or studies.\nKey aspects of consistency in research include:\n\nReplicability: The ability to reproduce study results using the same methods and data.\nRobustness: The stability of findings across different analytical approaches or slight variations in methodology.\nConvergence: The alignment of results from different studies or methods investigating the same phenomenon.\nLongitudinal Consistency: The stability of findings over time, especially important in longitudinal studies.\n\nEnsuring consistency in research involves: - Using standardized procedures and measures - Thoroughly documenting methods and analytical decisions - Conducting replication studies - Meta-analyses to synthesize findings across multiple studies",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#balancing-reliability-validity-and-consistency",
    "href": "chapter3b.html#balancing-reliability-validity-and-consistency",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.8 Balancing Reliability, Validity, and Consistency",
    "text": "7.8 Balancing Reliability, Validity, and Consistency\nWhile reliability, validity, and consistency are all crucial for high-quality research, they sometimes involve trade-offs:\n\nA highly reliable measure might lack validity if it consistently measures the wrong thing.\nStriving for perfect internal validity (e.g., in tightly controlled lab experiments) might reduce external validity.\nEnsuring high consistency across diverse contexts might require sacrificing some degree of precision or depth in specific situations.\n\nResearchers must carefully balance these aspects based on their research questions and the nature of their study. A comprehensive understanding of reliability, validity, and consistency helps in designing robust studies, interpreting results accurately, and contributing meaningfully to the body of scientific knowledge.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#bias-variance-tradeoff",
    "href": "chapter3b.html#bias-variance-tradeoff",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.9 Bias-Variance Tradeoff",
    "text": "7.9 Bias-Variance Tradeoff\nThe concepts of reliability and validity are closely related to the statistical notion of the bias-variance tradeoff. This tradeoff is fundamental in machine learning and statistical modeling.\n\nBias refers to the error introduced by approximating a real-world problem with a simplified model. High bias can lead to underfitting.\nVariance refers to the error introduced by the model’s sensitivity to small fluctuations in the training set. High variance can lead to overfitting.\n\nLet’s visualize this concept with a simplified plot:\n\nx &lt;- seq(0, 10, length.out = 100)\ny_true &lt;- sin(x)\ny_low_bias_high_var &lt;- y_true + rnorm(100, 0, 0.3)\ny_high_bias_low_var &lt;- 0.5 * x\n\ndf &lt;- data.frame(x = rep(x, 3),\n                 y = c(y_true, y_low_bias_high_var, y_high_bias_low_var),\n                 type = rep(c(\"True Function\", \"Low Bias, High Variance\", \"High Bias, Low Variance\"), each = 100))\n\nggplot(df, aes(x = x, y = y, color = type)) +\n  geom_line() +\n  geom_point(data = subset(df, type != \"True Function\"), alpha = 0.5) +\n  scale_color_manual(values = c(\"black\", \"blue\", \"red\")) +\n  labs(title = \"Bias-Variance Tradeoff\",\n       x = \"X\",\n       y = \"Y\",\n       color = \"Model Type\") +\n  theme_minimal()\n\n\n\n\nVisualization of Bias-Variance Tradeoff\n\n\n\n\nIn this plot: - The black line represents the true underlying function. - The blue points represent a model with low bias but high variance. It follows the true function closely on average but has a lot of noise. - The red line represents a model with high bias but low variance. It consistently underestimates the true function but has less noise.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  },
  {
    "objectID": "chapter3b.html#accuracy-and-precision",
    "href": "chapter3b.html#accuracy-and-precision",
    "title": "7  Reliability and Validity in Data Science Research",
    "section": "7.10 Accuracy and Precision",
    "text": "7.10 Accuracy and Precision\nThe concepts of accuracy and precision are closely related to validity and reliability:\n\nAccuracy refers to how close a measurement is to the true value (similar to validity).\nPrecision refers to how consistent or reproducible the measurements are (similar to reliability).\n\nWe can visualize these concepts using a simplified target analogy:\n\nlibrary(ggplot2)\nlibrary(ggforce)\n\ncreate_points &lt;- function(n, x_center, y_center, spread) {\n  data.frame(\n    x = rnorm(n, x_center, spread),\n    y = rnorm(n, y_center, spread)\n  )\n}\n\nset.seed(101)\npoints &lt;- rbind(\n  cbind(create_points(20, 0, 0, 0.1), type = \"High Accuracy\\nHigh Precision\"),\n  cbind(create_points(20, 0.5, 0.5, 0.1), type = \"Low Accuracy\\nHigh Precision\"),\n  cbind(create_points(20, 0, 0, 0.3), type = \"High Accuracy\\nLow Precision\"),\n  cbind(create_points(20, 0.5, 0.5, 0.3), type = \"Low Accuracy\\nLow Precision\")\n)\n\nggplot(points, aes(x, y)) +\n  geom_circle(aes(x0 = 0, y0 = 0, r = 1), color = \"black\", fill = NA) +\n  geom_circle(aes(x0 = 0, y0 = 0, r = 0.5), color = \"black\", fill = NA) +\n  geom_point(color = \"red\", size = 2) +\n  facet_wrap(~type) +\n  coord_fixed(xlim = c(-1.1, 1.1), ylim = c(-1.1, 1.1)) +\n  theme_minimal() +\n  theme(axis.text = element_blank(), axis.title = element_blank()) +\n  labs(title = \"Accuracy vs Precision\")\n\n\n\n\nVisualization of Accuracy vs Precision\n\n\n\n\nIn this visualization: - High accuracy means the points are close to the center (bullseye). - High precision means the points are tightly clustered. - Each panel represents a different combination of accuracy and precision.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Reliability and Validity in Data Science Research</span>"
    ]
  }
]